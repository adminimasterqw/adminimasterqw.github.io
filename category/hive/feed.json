{
    "version": "https://jsonfeed.org/version/1",
    "title": "Andrésen • All posts by \"hive\" category",
    "description": "",
    "home_page_url": "https://methiony.work",
    "items": [
        {
            "id": "https://methiony.work/2020/12/04/Hadoop/Hive/course-5/Hive%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/",
            "url": "https://methiony.work/2020/12/04/Hadoop/Hive/course-5/Hive%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/",
            "title": "Hive的基本概念",
            "date_published": "2020-12-04T01:23:45.000Z",
            "content_html": "<div class=\"note info\">\n<p>以下为个人学习笔记<br />\n课程： 大数据自学教程 Hadoop 从零到精通完整版 @<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vNTg2Mzg5MDQ5\">黑马程序员大数据教程</span><br />\n<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMWVrNHkxMTdZcQ==\"> https://www.bilibili.com/video/BV1ek4y117Yq</span></p>\n</div>\n<h1 id=\"1hive的基本概念\"><a class=\"anchor\" href=\"#1hive的基本概念\">#</a> 1.Hive 的基本概念</h1>\n<h2 id=\"11hive简介\"><a class=\"anchor\" href=\"#11hive简介\">#</a> 1.1.Hive 简介</h2>\n<h3 id=\"hive的概念\"><a class=\"anchor\" href=\"#hive的概念\">#</a> Hive 的概念</h3>\n<p>Hve 是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供类 SQL 查询功能<br />\n其本质是将 SQL 转换为 MapReduce 的任务进行运算，底层由 HDFS 来提供数据的存储，说白了 hive 可以理解为一个将 SQL 转换为 MapReduce 的任务的工具，甚至更进一步可以说 hive 就是一个 Map Reduce 的客户端</p>\n<h3 id=\"hive的优点\"><a class=\"anchor\" href=\"#hive的优点\">#</a> Hive 的优点</h3>\n<p>1、采用类 SQL 语法去操作数据，提供快速开发的能力<br />\n 2、避免了去写 MapReduce, 减少开发人员的学习成本<br />\n 3、功能扩展很方便</p>\n<p>4、用户接口：包括 CLI、JDBC/ODBC、 WebGUI, 其中，CLI (command line interface) 为 shell 命令行；JDBC/ODBC 是 Hive 的 JAVA 实现，与传统数据库 JDBC 类似；WebGUI 是通过浏览器访问 Hive<br />\n5、元数据存储：通常是存储在关系数据库如 mysql/derby 中。Hve 将元数据存储在数据库中。Hive 中的元数据包括表的名字，表的列和分区及其属性，表的属性 (是否为外部表等), 表的数据所在目录等<br />\n 6、解释器、编译器、优化器、执行嚣：完成 HQL 査询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在 HDFS 中，并在随后有 MapReduce 调用执行</p>\n<h2 id=\"12hive与-hadoop的关系\"><a class=\"anchor\" href=\"#12hive与-hadoop的关系\">#</a> 1.2.Hive 与 Hadoop 的关系</h2>\n<p>Hive 利用 HDFS 存储数据利用 MapReduce 查询分析数据</p>\n<h2 id=\"13hive与传统数据库对比\"><a class=\"anchor\" href=\"#13hive与传统数据库对比\">#</a> 1.3.Hive 与传统数据库对比</h2>\n<p>hive 用于海量数据的离线数据分析</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Hive</th>\n<th>RDBMS</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>查询语言</td>\n<td>HQL</td>\n<td>SQL</td>\n</tr>\n<tr>\n<td>数据存储</td>\n<td>HDFS</td>\n<td>Raw Device or Local FS</td>\n</tr>\n<tr>\n<td>执行</td>\n<td>MapReduce</td>\n<td>Excutor</td>\n</tr>\n<tr>\n<td>执行延迟</td>\n<td>高</td>\n<td>低</td>\n</tr>\n<tr>\n<td>处理数据规模</td>\n<td>大</td>\n<td>小</td>\n</tr>\n<tr>\n<td>索引</td>\n<td>0.8 版本后加入位图索引</td>\n<td>复杂的索引</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"14hive的安装\"><a class=\"anchor\" href=\"#14hive的安装\">#</a> 1.4.Hive 的安装</h2>\n<p>下载地址为:http:/archive.apache.org/dist/<br />\n 下载之后，将我们的安装包上传到第三台机器的 /usr/local/src 目录下面去</p>\n<h3 id=\"第一步上传并解压安装包\"><a class=\"anchor\" href=\"#第一步上传并解压安装包\">#</a> 第一步：上传并解压安装包</h3>\n<p>将我们的 hive 的安装包上传到第三台服务器的 /usr/local/src 路径下，然后进行解压</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">cd</span> /usr/local/src </pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token function\">tar</span> -zxvf apache-hive-1.1.0-bin.tar.gz</pre></td></tr></table></figure><h3 id=\"第二步修改hive的配置文件\"><a class=\"anchor\" href=\"#第二步修改hive的配置文件\">#</a> 第二步：修改 hive 的配置文件</h3>\n<p>修改 <span class=\"exturl\" data-url=\"aHR0cDovL2hpdmUtZW55LnNo\">hive-eny.sh</span></p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">cd</span> /usr/local/src/apache-hive-1.1.0-bin/conf</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token function\">cp</span> hive-env.sh.template hive-env.sh</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">HADOOP_HOME</span><span class=\"token operator\">=</span>/usr/local/src/hadoop-2.6.0</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">HIVE_CONF_DIR</span><span class=\"token operator\">=</span>/usr/local/src/apache-hive-1.1.0/conf</pre></td></tr></table></figure><p>测试启动 hive</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token punctuation\">[</span>root@node01 hive-1.1.0<span class=\"token punctuation\">]</span><span class=\"token comment\"># bin/hive</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token comment\">#若终端启动失败，则进入 hadoop 安装目录下的 share/hadoop/yarn/lib 下删除 jline 的 jar 文件。再启动 hive 即可</span></pre></td></tr></table></figure><figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token function\">vi</span> hive-site.xml</pre></td></tr></table></figure><figure class=\"highlight xml\"><figcaption data-lang=\"XML\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token prolog\">&lt;?xml version=\"1.0\"?></span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token prolog\">&lt;?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?></span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>configuration</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>           <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>javax.jdo.option.ConnectionURL<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>           <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>jdbc:mysql://master:3306/metastore?createDatabaseIfNotExist=true<span class=\"token entity named-entity\" title=\"&amp;\">&amp;amp;</span>useSSL=false<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>           <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>description</span><span class=\"token punctuation\">></span></span>JDBC connect string for a JDBC metastore<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>description</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>           <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>javax.jdo.option.ConnectionDriverName<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>           <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>com.mysql.jdbc.Driver<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>           <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>description</span><span class=\"token punctuation\">></span></span>Driver class name for a JDBC metastore<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>description</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>javax.jdo.option.ConnectionUserName<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>root<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>description</span><span class=\"token punctuation\">></span></span>username to use against metastore database<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>description</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>javax.jdo.option.ConnectionPassword<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>123456<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>description</span><span class=\"token punctuation\">></span></span>password to use against metastore database<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>description</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>configuration</span><span class=\"token punctuation\">></span></span></pre></td></tr></table></figure><h3 id=\"第三步配置hive的环境变量可省略\"><a class=\"anchor\" href=\"#第三步配置hive的环境变量可省略\">#</a> 第三步：配置 hive 的环境变量（可省略）</h3>\n<p>node03 服务器执行以下命令配置 hive 的环境变量</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token function\">vi</span> /etc/profile</pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">HIVE_HOME</span><span class=\"token operator\">=</span>/usr/local/src/apache-hive-1.1.1-bin</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\"><span class=\"token environment constant\">PATH</span></span><span class=\"token operator\">=</span>:<span class=\"token variable\">$SHIVE_HOME</span>/bin:<span class=\"token environment constant\">$PATH</span></pre></td></tr></table></figure><h3 id=\"第四步添加mysql的连接驱动包\"><a class=\"anchor\" href=\"#第四步添加mysql的连接驱动包\">#</a> 第四步：添加 mysql 的连接驱动包</h3>\n<p>hive 使用 mysql 作为元数据存储，必然需要连接 mysql 数据库，所以我们添加一个 mysql 的连接驱动包到 hive 的安装目录下，然后就可以准备启动 hive 了</p>\n<p>将我们准备好的 mysql-connector-java-5.1.38.jar 这个 jar 包直接上传到<br />\n /usr/local/src/ apache-hive1.1.0-bin/1ib 这个目录下即可<br />\n至此，hive 的安装部署已经完成。</p>\n<h2 id=\"15hive的交互方式\"><a class=\"anchor\" href=\"#15hive的交互方式\">#</a> 1.5.Hive 的交互方式</h2>\n<h3 id=\"客户端操作\"><a class=\"anchor\" href=\"#客户端操作\">#</a> 客户端操作</h3>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">cd</span> /usr/local/src/apache-hive-1.1.1-bin/</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>bin/hive</pre></td></tr></table></figure><p>创建一个数据库</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>create database <span class=\"token keyword\">if</span> not exists mytest<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h3 id=\"非客户端操作\"><a class=\"anchor\" href=\"#非客户端操作\">#</a> 非客户端操作</h3>\n<p>使用 sq1 语句或者 sq1 脚本进行交互不进入 hive 的客户端直接执行 hive 的 hql 语句</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">cd</span> /usr/local/src/apache-hive-1.1.1-bin/</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>bin/hive -e <span class=\"token string\">\"create database if not exists mytest;\"</span></pre></td></tr></table></figure><p>或者将我们的 hql 语句写成一个 sql 脚本然后执行</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">cd</span> /usr/local/src</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token function\">vi</span> hive.sql</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>create database <span class=\"token keyword\">if</span> not exists mytest<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>use mytest</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>create table stu<span class=\"token punctuation\">(</span>id int, name string<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>通过 hive-f 来执行我们的 sql 脚本</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>bin/hive -f /usr/local/src/hive.sql</pre></td></tr></table></figure>",
            "tags": []
        },
        {
            "id": "https://methiony.work/2020/12/04/Hadoop/Hive/course-5/Hive%E7%9A%84%E8%B0%83%E4%BC%98/",
            "url": "https://methiony.work/2020/12/04/Hadoop/Hive/course-5/Hive%E7%9A%84%E8%B0%83%E4%BC%98/",
            "title": "Hive的调优",
            "date_published": "2020-12-04T00:48:12.000Z",
            "content_html": "<div class=\"note info\">\n<p>以下为个人学习笔记<br />\n课程： 大数据自学教程 Hadoop 从零到精通完整版 @<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vNTg2Mzg5MDQ5\">黑马程序员大数据教程</span><br />\n<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMWVrNHkxMTdZcQ==\"> https://www.bilibili.com/video/BV1ek4y117Yq</span></p>\n</div>\n",
            "tags": []
        },
        {
            "id": "https://methiony.work/2020/12/04/Hadoop/Hive/course-5/Hive%E7%9A%84%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F/",
            "url": "https://methiony.work/2020/12/04/Hadoop/Hive/course-5/Hive%E7%9A%84%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F/",
            "title": "Hive的数据存储格式",
            "date_published": "2020-12-04T00:47:45.000Z",
            "content_html": "<div class=\"note info\">\n<p>以下为个人学习笔记<br />\n课程： 大数据自学教程 Hadoop 从零到精通完整版 @<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vNTg2Mzg5MDQ5\">黑马程序员大数据教程</span><br />\n<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMWVrNHkxMTdZcQ==\"> https://www.bilibili.com/video/BV1ek4y117Yq</span></p>\n</div>\n<h1 id=\"hive的数据存储格式\"><a class=\"anchor\" href=\"#hive的数据存储格式\">#</a> hive 的数据存储格式</h1>\n<p>Hive 支持的存储数的格式主要有: TEXTFILE (行式存储)、SEQUENCEFILE (行式存储)、ORC (列式存储)、 PARQUET (列式存储)。</p>\n<h2 id=\"列式存储和行式存储\"><a class=\"anchor\" href=\"#列式存储和行式存储\">#</a> 列式存储和行式存储</h2>\n<h3 id=\"行存储的特点\"><a class=\"anchor\" href=\"#行存储的特点\">#</a> 行存储的特点:</h3>\n<p>査询满足条件的一整行数据的时候，列存储则需要去毎个聚集的字段找到对<br />\n应的毎个列的值，行存储只需要找到其中一个值，其余的值都在相邻地方，所以此时行存储查询的速度更快</p>\n<h3 id=\"列存储的特点\"><a class=\"anchor\" href=\"#列存储的特点\">#</a> 列存储的特点:</h3>\n<p>因为毎个字段的数据聚集存储，在査询只需要少数几个字段的时候，能大大<br />\n减少读取的数据量；每个字段的数据类型一定是相同的，列式存储可以针对性的设计更好的设计压缩算法</p>\n<p>TEXTFILE 和 SEQUENCEFILE 的存储格式都是基于行存储的；<br />\n0RC 和 PARQUET 是基于列式存储的。</p>\n",
            "tags": []
        },
        {
            "id": "https://methiony.work/2020/12/04/Hadoop/Hive/course-5/Hive%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9/",
            "url": "https://methiony.work/2020/12/04/Hadoop/Hive/course-5/Hive%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9/",
            "title": "Hive的数据压缩",
            "date_published": "2020-12-04T00:47:27.000Z",
            "content_html": "<div class=\"note info\">\n<p>以下为个人学习笔记<br />\n课程： 大数据自学教程 Hadoop 从零到精通完整版 @<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vNTg2Mzg5MDQ5\">黑马程序员大数据教程</span><br />\n<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMWVrNHkxMTdZcQ==\"> https://www.bilibili.com/video/BV1ek4y117Yq</span></p>\n</div>\n<h1 id=\"hive的数据压缩\"><a class=\"anchor\" href=\"#hive的数据压缩\">#</a> Hive 的数据压缩</h1>\n<h2 id=\"压缩格式\"><a class=\"anchor\" href=\"#压缩格式\">#</a> 压缩格式</h2>\n<table>\n<thead>\n<tr>\n<th>压缩格式</th>\n<th>对应的编码 / 解码器</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>DEFLATE</td>\n<td>org.apache.hadoop.io.compress.DefaultCodec</td>\n</tr>\n<tr>\n<td>gzip</td>\n<td>org.apache.hadoop.io.compress.GzipCodec</td>\n</tr>\n<tr>\n<td>bzip</td>\n<td>org.apache.hadoop.io.compress.BZip2Codec</td>\n</tr>\n<tr>\n<td>LZO</td>\n<td>com.hadoop.compression.lzo.LzopCodec</td>\n</tr>\n<tr>\n<td>LZ4</td>\n<td>org.apache.hadoop.io.compress.Lz4Codec</td>\n</tr>\n<tr>\n<td>Snappy</td>\n<td>org.apache.hadoop.io.compress.SnappyCodef</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"压缩性能的比较\"><a class=\"anchor\" href=\"#压缩性能的比较\">#</a> 压缩性能的比较</h2>\n<table>\n<thead>\n<tr>\n<th>压缩算法</th>\n<th>原始文件大小</th>\n<th>压缩文件大小</th>\n<th>压缩速度</th>\n<th>解压速度</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>gzip</td>\n<td>8.3GB</td>\n<td>1.8GB</td>\n<td>17.5MB/s</td>\n<td>58MB/s</td>\n</tr>\n<tr>\n<td>bzip2</td>\n<td>8.3GB</td>\n<td>1.1GB</td>\n<td>2.4MB/s</td>\n<td>9.5MB/s</td>\n</tr>\n<tr>\n<td>LZO</td>\n<td>8.3GB</td>\n<td>2.9GB</td>\n<td>49.3MB/s</td>\n<td>74.6MB/s</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"开启-reduce输出阶段压缩\"><a class=\"anchor\" href=\"#开启-reduce输出阶段压缩\">#</a> 开启 Reduce 输出阶段压缩</h2>\n<p>当 Hⅳe 将输出写入到表中时，输出内容同样可以进行压缩。属性 hive.exec.compress.output 控制着这个功能。用户可能需要保持默认设置文件中的默认值 false, 这样默认的输出就是非压缩的纯文本文件了。用户可以通过在查询语句或执行脚本中设置这个值为 true, 来开启输出结果压缩功能。<br />\n案例实操<br />\n开启 Hive 最终输出数据压缩功能</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">set</span> hive.exec.compress.output<span class=\"token operator\">=</span>true<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>开启 mapreduce 最终输出数据压缩</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">set</span> mapreduce.output.fileoutputformat.compress<span class=\"token operator\">=</span>true<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>设置 mapreduce 最终数据输出压缩方式</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">set</span> mapreduce.output.fileoutputformat.compress.codec<span class=\"token operator\">=</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>org.apache.hadoop.io.compress.SnappyCodec<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>设置 mapreduce 最终数据输出压缩为块压缩</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">set</span> mapreduce.output.fileoutputformat.compress.type <span class=\"token operator\">=</span> BLOCK<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>测试一下输出结果是否是压缩文件</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>insert overwrite <span class=\"token builtin class-name\">local</span> directory <span class=\"token string\">'/export/servers/snappy'</span> <span class=\"token keyword\">select</span> * from score distribute by s_id <span class=\"token function\">sort</span> by s_id desc<span class=\"token punctuation\">;</span></pre></td></tr></table></figure>",
            "tags": []
        },
        {
            "id": "https://methiony.work/2020/12/04/Hadoop/Hive/course-5/Hive%E7%9A%84%E5%87%BD%E6%95%B0/",
            "url": "https://methiony.work/2020/12/04/Hadoop/Hive/course-5/Hive%E7%9A%84%E5%87%BD%E6%95%B0/",
            "title": "Hive的函数",
            "date_published": "2020-12-04T00:47:10.000Z",
            "content_html": "<div class=\"note info\">\n<p>以下为个人学习笔记<br />\n课程： 大数据自学教程 Hadoop 从零到精通完整版 @<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vNTg2Mzg5MDQ5\">黑马程序员大数据教程</span><br />\n<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMWVrNHkxMTdZcQ==\"> https://www.bilibili.com/video/BV1ek4y117Yq</span></p>\n</div>\n<h1 id=\"hive的函数\"><a class=\"anchor\" href=\"#hive的函数\">#</a> Hive 的函数</h1>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token number\">1</span>.查看系统自带的函数</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>hive<span class=\"token operator\">></span> show functions<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token number\">2</span>显示自带的函数的用法</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>hive<span class=\"token operator\">></span> desc <span class=\"token keyword\">function</span> upper<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token number\">3</span>.详细显示自带的函数的用法</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>hive<span class=\"token operator\">></span> desc <span class=\"token keyword\">function</span> extended upper<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h2 id=\"1-常用函数\"><a class=\"anchor\" href=\"#1-常用函数\">#</a> 1、常用函数</h2>\n<p>求总行数 (count)</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> count<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> from score<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>求分数的最大值 (max</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> max<span class=\"token punctuation\">(</span>s_score<span class=\"token punctuation\">)</span> from score<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>求分数的最小值 (min)</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> min<span class=\"token punctuation\">(</span>s_score<span class=\"token punctuation\">)</span> from score<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>求分数的总和 (sum)</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> sum<span class=\"token punctuation\">(</span>s_score<span class=\"token punctuation\">)</span> from score<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>求分数的平均值 (avg)</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> avg<span class=\"token punctuation\">(</span>s_score<span class=\"token punctuation\">)</span> from score<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h3 id=\"常用内置函数\"><a class=\"anchor\" href=\"#常用内置函数\">#</a> 常用内置函数</h3>\n<p>字符串连接函数: concat</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> concat<span class=\"token punctuation\">(</span><span class=\"token string\">'abe'</span>,<span class=\"token string\">'def'</span>,<span class=\"token string\">'gh'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>带分隔符字符串连接函数: concat ws</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> concat_ws<span class=\"token punctuation\">(</span><span class=\"token string\">','</span>,<span class=\"token string\">'abc'</span>,<span class=\"token string\">'def'</span>,<span class=\"token string\">'gh'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>cast 类型转换</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> cast<span class=\"token punctuation\">(</span><span class=\"token number\">1.5</span> as int<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>get_json_object (json 解析函数，用来处理 json, 必须是 json 格式)</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> get_json_object<span class=\"token punctuation\">(</span><span class=\"token string\">'&#123;\"name\":\"jack\",\"age\": \"20\"&#125;'</span>,<span class=\"token string\">'$.name'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>URL 解析函数</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> parse_url<span class=\"token punctuation\">(</span><span class=\"token string\">'http://facebook.com/path1/p.php?k1=v1&amp;k2=v2#Ref1'</span>,<span class=\"token string\">'HOST'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h2 id=\"2-limit语句\"><a class=\"anchor\" href=\"#2-limit语句\">#</a> 2、LIMIT 语句</h2>\n<p>典型的查询会返回多行数据。LIMIT 子句用于限制返回的行数。</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> * from score limit <span class=\"token number\">3</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h2 id=\"3-where语句\"><a class=\"anchor\" href=\"#3-where语句\">#</a> 3、where 语句</h2>\n<p>查询分数等于 80 的所有的数据</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> * from score where s_score <span class=\"token operator\">=</span> <span class=\"token number\">80</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>查询分数在 80 到 100 的所有数据</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> * from score where s_score between <span class=\"token number\">80</span> and <span class=\"token number\">100</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>查询成绩空的所有数据</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> * from score where s_score is null<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>查询成绩是 80 和 90 的数据</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> * from score where s_score in<span class=\"token punctuation\">(</span><span class=\"token number\">80</span>, <span class=\"token number\">90</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h2 id=\"4-lke和rlke\"><a class=\"anchor\" href=\"#4-lke和rlke\">#</a> 4、LKE 和 RLKE</h2>\n<p>1. 使用 LIKE 运算选择类似的值<br />\n 2. 选择条件可以包含字符或数字</p>\n<figure class=\"highlight xml\"><figcaption data-lang=\"XML\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>% 代表零个或多个字符(任意个字符)。</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>_代表一个字符。</pre></td></tr></table></figure><p>3.RLKE 子句是 Hive 中这个功能的一个扩展，其可以通过 Java 的正则表达式这个更强大的语言来指定匹配条件。</p>\n<p>4. 案例实操<br />\n查找以 8 开头的所有成绩</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> * from score where s_score like <span class=\"token string\">'8%'</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>查找第二个数值为 9 的所有成绩数据</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> * from score where s_score like <span class=\"token string\">'_9%'</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>查找 sid 中含 1 的数据</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> * from score where s_id rlike <span class=\"token string\">'[1]'</span><span class=\"token punctuation\">;</span> <span class=\"token comment\"># like '%1%'</span></pre></td></tr></table></figure><h2 id=\"5-逻辑运算符\"><a class=\"anchor\" href=\"#5-逻辑运算符\">#</a> 5、逻辑运算符</h2>\n<table>\n<thead>\n<tr>\n<th>操作符</th>\n<th>含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>AND</td>\n<td>逻辑并</td>\n</tr>\n<tr>\n<td>OR</td>\n<td>逻辑或</td>\n</tr>\n<tr>\n<td>NOT</td>\n<td>逻辑否</td>\n</tr>\n</tbody>\n</table>\n<p>查询成绩大于 80, 并且 s_id 是 01 的数据</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> * from score where s_score <span class=\"token operator\">></span><span class=\"token number\">80</span> and s_id <span class=\"token operator\">=</span> <span class=\"token string\">'01'</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>查询成绩大于 80, 或者 sid 是 01 的数</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> * from score where s_score <span class=\"token operator\">></span><span class=\"token number\">80</span> or s_id <span class=\"token operator\">=</span><span class=\"token string\">'01'</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>查询 s_id 不是 01 和 02 的学生</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> * from score where s_id not <span class=\"token keyword\">in</span> <span class=\"token punctuation\">(</span><span class=\"token string\">'01'</span>,<span class=\"token string\">'02'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure>",
            "tags": []
        },
        {
            "id": "https://methiony.work/2020/12/04/Hadoop/Hive/course-5/Hive-Shell%E5%8F%82%E6%95%B0/",
            "url": "https://methiony.work/2020/12/04/Hadoop/Hive/course-5/Hive-Shell%E5%8F%82%E6%95%B0/",
            "title": "Hive Shell参数",
            "date_published": "2020-12-04T00:46:47.000Z",
            "content_html": "<div class=\"note info\">\n<p>以下为个人学习笔记<br />\n课程： 大数据自学教程 Hadoop 从零到精通完整版 @<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vNTg2Mzg5MDQ5\">黑马程序员大数据教程</span><br />\n<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMWVrNHkxMTdZcQ==\"> https://www.bilibili.com/video/BV1ek4y117Yq</span></p>\n</div>\n<h1 id=\"hive-shell参数\"><a class=\"anchor\" href=\"#hive-shell参数\">#</a> Hive shell 参数</h1>\n<h2 id=\"hive命令行\"><a class=\"anchor\" href=\"#hive命令行\">#</a> Hive 命令行</h2>\n<p>语法结构</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>bin/hive <span class=\"token punctuation\">[</span>-hiveconf <span class=\"token assign-left variable\">x</span><span class=\"token operator\">=</span>y<span class=\"token punctuation\">]</span> * <span class=\"token punctuation\">[</span><span class=\"token operator\">&lt;</span>-i filename<span class=\"token operator\">></span><span class=\"token punctuation\">]</span> * <span class=\"token punctuation\">[</span><span class=\"token operator\">&lt;</span>-f filename<span class=\"token operator\">>|</span><span class=\"token operator\">&lt;</span>-e query-string<span class=\"token operator\">></span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>-S<span class=\"token punctuation\">]</span></pre></td></tr></table></figure><p>说明<br />\n - i\t从文件初始化 HQL<br />\n-e\t从命令行执行指定的 HQL<br />\n-f\t执行 HQL 脚本<br />\n - v\t输出执行的 HQL 语句到控制台<br />\n - p \tconnect to Hive Server on port number<br />\n-hiveconf  x = y Use this to set hive/hadoop configuration variables. 设置 hive 运行时候的参数配置</p>\n<p>开发 Hive 应用时，不可避免地需要设定 Hive 的参数。设定 Hive 的参数可以调优 HQL 代码的执行效率，或帮助定位问题。<br />\n对于一般参数，有以下三种设定方式<br />\n配置文件<br />\n命令行参数<br />\n参数声明</p>\n<h2 id=\"配置文件\"><a class=\"anchor\" href=\"#配置文件\">#</a> 配置文件：</h2>\n<p>Hive 的配置文件包括<br />\n用户自定义配置文件:</p>\n<figure class=\"highlight xml\"><figcaption data-lang=\"XML\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>$HIVE_CONF_DIR/hive-site.xml</pre></td></tr></table></figure><p>默认配置文件:</p>\n<figure class=\"highlight xml\"><figcaption data-lang=\"XML\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>$HIVE_CONE_DIR/hive-default.xml</pre></td></tr></table></figure><p>用户自定义配置会覆盖默认配置。</p>\n<p>另外，Hive 会读入 Hadoop 的配置，因为 Hive 是作为 Hadoop 的客户端启动的，Hive 的配置会覆盖 Hadoop 的配置。<br />\n配置文件的设定对本机启动的所有 Hive 进程都有效。</p>\n<h2 id=\"命令行参数\"><a class=\"anchor\" href=\"#命令行参数\">#</a> 命令行参数:</h2>\n<p>启动 Hive (客户端或 Server 方式) 时，可以在命令行添加 - hiveconf param= value 来设定参数，例如</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>bin/hive -hiveconf hive.root.logger<span class=\"token operator\">=</span>INFO,console</pre></td></tr></table></figure><p>这一设定对本次启动的 Session (对于 Server 方式启动，则是所有请求的 Sessions) 有效</p>\n<h2 id=\"参救声明\"><a class=\"anchor\" href=\"#参救声明\">#</a> 参救声明:</h2>\n<p>可以在 HQL 中使用 SET 关键字设定参数，例如</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">set</span> mapred.reduce.tasks<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>这一设定的作用域也是 session 级的。<br />\n上述三种设定方式的优先级依次递增。即参数声明覆盖命令行参数，命令行参数覆盖配置文件设定。注意某些系统级的参数，例如 log4j 相关的设定，必须用前两种方式设定，因为那些参数的读取在 Session 建立以前已经完了。</p>\n",
            "tags": []
        },
        {
            "id": "https://methiony.work/2020/12/04/Hadoop/Hive/course-5/Hive%E7%9A%84%E6%9F%A5%E8%AF%A2%E8%AF%AD%E6%B3%95/",
            "url": "https://methiony.work/2020/12/04/Hadoop/Hive/course-5/Hive%E7%9A%84%E6%9F%A5%E8%AF%A2%E8%AF%AD%E6%B3%95/",
            "title": "Hive的查询语法",
            "date_published": "2020-12-04T00:46:24.000Z",
            "content_html": "<div class=\"note info\">\n<p>以下为个人学习笔记<br />\n课程： 大数据自学教程 Hadoop 从零到精通完整版 @<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vNTg2Mzg5MDQ5\">黑马程序员大数据教程</span><br />\n<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMWVrNHkxMTdZcQ==\"> https://www.bilibili.com/video/BV1ek4y117Yq</span></p>\n</div>\n<h1 id=\"hive查询语法\"><a class=\"anchor\" href=\"#hive查询语法\">#</a> Hive 查询语法</h1>\n<h2 id=\"1-selec\"><a class=\"anchor\" href=\"#1-selec\">#</a> 1、SELEC</h2>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>SELECT <span class=\"token punctuation\">[</span>ALL <span class=\"token operator\">|</span> DISTINCT<span class=\"token punctuation\">]</span> select_expr, select_expr,<span class=\"token punctuation\">..</span>.</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>FROM table_reference</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token punctuation\">[</span>WHERE where_condition<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token punctuation\">[</span>GROUP BY col_list <span class=\"token punctuation\">[</span>HAVING condition<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token punctuation\">[</span>CLUSTER BY col_list <span class=\"token operator\">|</span> <span class=\"token punctuation\">[</span>DISTRIBUTE BY col_list<span class=\"token punctuation\">]</span> <span class=\"token punctuation\">[</span> SORT BY <span class=\"token operator\">|</span> ORDER BY col_list<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token punctuation\">[</span>LIMIT number<span class=\"token punctuation\">]</span></pre></td></tr></table></figure><p>order by 会对输入做全局排序，因此只有一个 reducer, 会导致当输入规模较大时，需要较长的计算时间。</p>\n<p>sort by 不是全局排序，其在数据进入 reducer 前完成排序。因此，如果用 sort by 进行排序，并且设置 mapred.reduce.tasks&gt;1, 则 sort by 只保证每个 reduce 的输出有序，不保证全局有序。</p>\n<p>distribute by (字段) 根据指定的字段将数据分到不同的 reducer, 且分发算法是 hash 散列.</p>\n<p>cluster by (字段) 除了具有 distribute by 的功能外，还会对该字段进行排序<br />\n因此，如果 distribute 和 sort 字段是同一个时，此时，cluster by= distribute by  + sort by</p>\n<h2 id=\"2-分组\"><a class=\"anchor\" href=\"#2-分组\">#</a> 2、分组</h2>\n<h3 id=\"21group-by语句\"><a class=\"anchor\" href=\"#21group-by语句\">#</a> 2.1.GROUP BY 语句</h3>\n<p>GROUP BY 语句通常会和聚合函数一起使用，按照一个或者多个列队结果进行分组，然后对每个组执行聚合操作。</p>\n<p>案例实操<br />\n计算每个学生的平均分数</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> s_id, avg<span class=\"token punctuation\">(</span>s_score<span class=\"token punctuation\">)</span> from score group by s_id<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>计算每个学生最高成绩</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> s_id ,max<span class=\"token punctuation\">(</span>s.score<span class=\"token punctuation\">)</span> from score group by s_id<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h3 id=\"22having语句\"><a class=\"anchor\" href=\"#22having语句\">#</a> 2.2.HAVING 语句</h3>\n<h4 id=\"having与-where不同点\"><a class=\"anchor\" href=\"#having与-where不同点\">#</a> having 与 where 不同点</h4>\n<p>where 针对表中的列发挥作用，查询数据；having 针对查询结果中的列发挥作用，筛<br />\n选数据。<br />\nwhere 后面不能写分组函数，而 hang 后面可以使用分组函数 having 只用于 group by 分组统计语句</p>\n<h4 id=\"案例实操\"><a class=\"anchor\" href=\"#案例实操\">#</a> 案例实操:</h4>\n<p>求每个学生的平均分数</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> s_id, avg<span class=\"token punctuation\">(</span>s_score<span class=\"token punctuation\">)</span> from score group by s_id<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>求每个学生平均分数大于 85 的人</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> s_id ,avg<span class=\"token punctuation\">(</span>s_score<span class=\"token punctuation\">)</span> avgscore from score group by s_id having avgscore <span class=\"token operator\">></span><span class=\"token number\">85</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h3 id=\"23join语句\"><a class=\"anchor\" href=\"#23join语句\">#</a> 2.3.JOIN 语句</h3>\n<p>等值 JOIN<br />\nHⅳve 支持通常的 SQL JOIN 语句，但是只支持等值连接，不支持非等值连接。<br />\n案例操作:</p>\n<p>查询分数对应的姓名</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> s.s_id, s.s_score, stu.s_name, stu.s_birth from score s <span class=\"token function\">join</span> student stu on s.s_id <span class=\"token operator\">=</span> stu s_id<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h3 id=\"24表的别名\"><a class=\"anchor\" href=\"#24表的别名\">#</a> 2.4. 表的别名</h3>\n<p>好处<br />\n使用别名可以简化查询。<br />\n使用表名前缀可以提高执行效率</p>\n<p>案例实操<br />\n合并老师与课程表</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> * from techer t <span class=\"token function\">join</span> course c on t.t_id <span class=\"token operator\">=</span> c.t_id<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h3 id=\"25内连接\"><a class=\"anchor\" href=\"#25内连接\">#</a> 2.5. 内连接</h3>\n<p>内连接：只有进行连接的两个表中都存在与连接条件相匹配的数据才会被保留下来。</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> * from techer t inner <span class=\"token function\">join</span> course c on t.t_id <span class=\"token operator\">=</span> c.t_id<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h3 id=\"26左外连接\"><a class=\"anchor\" href=\"#26左外连接\">#</a> 2.6. 左外连接</h3>\n<p>左外连接：JOIN 操作符左边表中符合 WHERE 子句的所有记录将会被返回。</p>\n<p>查询老师对应的课程</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> * from techer t left <span class=\"token function\">join</span> course c on t.t_id <span class=\"token operator\">=</span> c.t_id<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h3 id=\"27右外连接\"><a class=\"anchor\" href=\"#27右外连接\">#</a> 2.7. 右外连接</h3>\n<p>右外连接：JOIN 操作符右边表中符合 WHERE 子句的所有记录将会被返回。</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> * from techer t right <span class=\"token function\">join</span> course c on t.t_id <span class=\"token operator\">=</span> c.t_id<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h3 id=\"28多表连接\"><a class=\"anchor\" href=\"#28多表连接\">#</a> 2.8. 多表连接</h3>\n<p>注意：连接 n 个表，至少需要 n-1 个连接条件。例如：连接三个表，至少需要两个连接条件。<br />\n多表连接査询，查询老师对应的课程，以及对应的分数，对应的学生</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> * from teacher</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>left <span class=\"token function\">join</span> course c</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>on t.t_id <span class=\"token operator\">=</span> c.t_id</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>left <span class=\"token function\">join</span> score s</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>on s.c_id <span class=\"token operator\">=</span> c.c_id</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>left <span class=\"token function\">join</span> student stu</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>on s.s_id <span class=\"token operator\">=</span>  stu.s_id<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>大多数情况下，Hive 会对每对 JOIN 连接对象启动一个 MapReduce 任务。本例中会首先启动一个 MapReduce job 对表 techer 和表 course 进行连接操作，然后会再启动一个 MapReduce job 将第<br />\n个 MapReduce job 的输出和表 score; 进行连接操作。</p>\n<h2 id=\"3-排序\"><a class=\"anchor\" href=\"#3-排序\">#</a> 3、排序</h2>\n<h3 id=\"31全局排序\"><a class=\"anchor\" href=\"#31全局排序\">#</a> 3.1. 全局排序</h3>\n<p>Order By：全局排序，一个 reduce</p>\n<p>使用 ORDER BY 子句排序</p>\n<p>ASC (ascend): 升序 (默认)</p>\n<p>DESC (descend): 降序</p>\n<p>ORDER BY 子句在 SELECT 语句的结尾</p>\n<p>案例实操<br />\n查询学生的成绩，并按照分数降序排列</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>SELECT * FROM student s LEFT JOIN score sco ON s.s_id <span class=\"token operator\">=</span> sco.s_id ORDER BY sco.s_score DESC<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>查询学生的成绩，并按照分数升序排列</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>SELECT * FROM student s LEFT JOIN score sco ON s.s_id <span class=\"token operator\">=</span> sco.s_id ORDER BY sco.s_score asc<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h3 id=\"32别名排序\"><a class=\"anchor\" href=\"#32别名排序\">#</a> 3.2. 别名排序</h3>\n<p>按照分数的平均值排序</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> s_id, avg<span class=\"token punctuation\">(</span>s_score<span class=\"token punctuation\">)</span> avg from score group by s_id order by avg<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h3 id=\"33多个列排序\"><a class=\"anchor\" href=\"#33多个列排序\">#</a> 3.3. 多个列排序</h3>\n<p>按照学生 id 和平均成绩进行排序</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> s_id, avg<span class=\"token punctuation\">(</span>s_score<span class=\"token punctuation\">)</span> avg from score group by s_id order by s_id,avg<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h3 id=\"34局部排序\"><a class=\"anchor\" href=\"#34局部排序\">#</a> 3.4. 局部排序</h3>\n<p>每个 MapReduce 内部排序 (Sort By) 局部排序<br />\n Sort By：每个 MapReduce 内部进行排序，对全局结果集来说不是排序<br />\n设置 reduce 个数</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">set</span> mapreduce.job.reduces<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>查看设置 reduce 个数</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">set</span> mapreduce.job.reduces<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>查询成绩按照成绩降序排列</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> * from score <span class=\"token function\">sort</span> by s_score<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>将查询结果导入到文件中 (按照成绩降序排列)</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>insert overwrite <span class=\"token builtin class-name\">local</span> directory <span class=\"token string\">'/usr/local/src/hivedatas/sort'</span> <span class=\"token keyword\">select</span> * from score <span class=\"token function\">sort</span> by s_score<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h2 id=\"4-分区排序-distribute-by\"><a class=\"anchor\" href=\"#4-分区排序-distribute-by\">#</a> 4、分区排序 (DISTRIBUTE BY)</h2>\n<h3 id=\"41distribute-by\"><a class=\"anchor\" href=\"#41distribute-by\">#</a> 4.1.Distribute By</h3>\n<p>类似 MR 中 partition, 进行分区，结合 sort by 使用</p>\n<p>注意，Hive 要求 D| STRIBUTE BY 语句要写在 SORT BY 语句之前。</p>\n<p>对于 distribute by 进行测试，一定要分配多 reduce 进行处理，否则无法看到 distribute by 的效果</p>\n<p>案例实操:</p>\n<p>先按照学生 id 进行分区，再按照学生成绩进行排序。<br />\n设置 reduce 的个数，将我们对应的 s_id 划分到对应的 reduce 当中去</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">set</span> mapreduce.job.reduces<span class=\"token operator\">=</span><span class=\"token number\">7</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>通过 distribute by 进行数据的分区</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>insert overwrite <span class=\"token builtin class-name\">local</span> directory <span class=\"token string\">'/export/servers/hivedatas/sort'</span> <span class=\"token keyword\">select</span> * from score distribute by s_id <span class=\"token function\">sort</span> by s_score<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h3 id=\"42-cluster-by\"><a class=\"anchor\" href=\"#42-cluster-by\">#</a> 4.2. CLUSTER BY</h3>\n<p>当 distribute by 和 sort by 字段相同时，可以使用 cluster by 方式。</p>\n<p>cluster by 除了具有 distribute by 的功能外还兼具 sort by 的功能。但是排序只能是倒序排序，不能指定排序规则为 ASC 或者 DESC</p>\n<p>以下两种写法等价</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> * from score cluster by s_id<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">select</span> * from score distribute by s_id <span class=\"token function\">sort</span> by s_id<span class=\"token punctuation\">;</span></pre></td></tr></table></figure>",
            "tags": []
        },
        {
            "id": "https://methiony.work/2020/12/04/Hadoop/Hive/course-5/Hive%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/",
            "url": "https://methiony.work/2020/12/04/Hadoop/Hive/course-5/Hive%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/",
            "title": "Hive的基本操作",
            "date_published": "2020-12-04T00:46:02.000Z",
            "content_html": "<div class=\"note info\">\n<p>以下为个人学习笔记<br />\n课程： 大数据自学教程 Hadoop 从零到精通完整版 @<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vNTg2Mzg5MDQ5\">黑马程序员大数据教程</span><br />\n<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMWVrNHkxMTdZcQ==\"> https://www.bilibili.com/video/BV1ek4y117Yq</span></p>\n</div>\n<h1 id=\"1hive的基本操作\"><a class=\"anchor\" href=\"#1hive的基本操作\">#</a> 1.Hive 的基本操作</h1>\n<h2 id=\"11数据库操作\"><a class=\"anchor\" href=\"#11数据库操作\">#</a> 1.1 数据库操作</h2>\n<h3 id=\"111创建数据库\"><a class=\"anchor\" href=\"#111创建数据库\">#</a> 1.1.1 创建数据库</h3>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>create database <span class=\"token keyword\">if</span> not exists myhive<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>use myhive<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>说明:hive 的表存放位置模式是由 hive-site.xml 当中的一个属性指定的</p>\n<figure class=\"highlight xml\"><figcaption data-lang=\"XML\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>hive.metastore.warehouse.dir<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>/user/hive/warehouse<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span></pre></td></tr></table></figure><h3 id=\"112刨建数据库并指定位置\"><a class=\"anchor\" href=\"#112刨建数据库并指定位置\">#</a> 1.1.2 刨建数据库并指定位置</h3>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>create database myhive2 location <span class=\"token string\">'/myhive2'</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h3 id=\"113设置数据库键值对信息\"><a class=\"anchor\" href=\"#113设置数据库键值对信息\">#</a> 1.1.3 设置数据库键值对信息</h3>\n<p>数据库可以有一些描述性的键值对信息，在创建时添加:</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>create database foo with dbproperties <span class=\"token punctuation\">(</span><span class=\"token string\">'owner'</span><span class=\"token operator\">=</span><span class=\"token string\">'itcast'</span>,</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token string\">'date'</span><span class=\"token operator\">=</span><span class=\"token string\">'28198128'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>查看数据库的键值对信息</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>describe database extended foo<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>修改数据库的键值对信息</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>alter database foo <span class=\"token builtin class-name\">set</span> dbproperties <span class=\"token punctuation\">(</span><span class=\"token string\">'owner'</span><span class=\"token operator\">=</span><span class=\"token string\">'itheima'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h3 id=\"114查看数据库更多详细信息\"><a class=\"anchor\" href=\"#114查看数据库更多详细信息\">#</a> 1.1.4 查看数据库更多详细信息</h3>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>desc database extended myhive2<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h3 id=\"115删除数据库\"><a class=\"anchor\" href=\"#115删除数据库\">#</a> 1.1.5 删除数据库</h3>\n<p>删除一个空数据库，如果数据库下面有数据表，那么就会报错</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>drop database myhive2<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>强制删除数据库，包含数据库下面的表一起删除</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>drop database myhive cascade<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h2 id=\"12数据库表操作\"><a class=\"anchor\" href=\"#12数据库表操作\">#</a> 1.2 数据库表操作</h2>\n<h3 id=\"121创建表的语法\"><a class=\"anchor\" href=\"#121创建表的语法\">#</a> 1.2.1 创建表的语法</h3>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>create <span class=\"token punctuation\">[</span>external<span class=\"token punctuation\">]</span> table <span class=\"token punctuation\">[</span>if not exists<span class=\"token punctuation\">]</span> table_name<span class=\"token punctuation\">(</span>col_name data_type<span class=\"token punctuation\">[</span>comment <span class=\"token string\">'字段描述信息'</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>col_name data_type<span class=\"token punctuation\">[</span>comment <span class=\"token string\">'字段描述信息'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token punctuation\">[</span>comment <span class=\"token string\">'表的描述信息'</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token punctuation\">[</span>partitioned by <span class=\"token punctuation\">(</span>col_name data-type,<span class=\"token punctuation\">..</span>.<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token punctuation\">[</span>clustered by <span class=\"token punctuation\">(</span>col_name,col_name,<span class=\"token punctuation\">..</span>.<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token punctuation\">[</span>sorted by <span class=\"token punctuation\">(</span>col_name <span class=\"token punctuation\">[</span>asc<span class=\"token operator\">|</span>desc<span class=\"token punctuation\">]</span><span class=\"token punctuation\">..</span>.<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>into num_buckets buckets<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token punctuation\">[</span>row <span class=\"token function\">format</span> row_format<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token punctuation\">[</span>stored as <span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token punctuation\">[</span>location <span class=\"token string\">'指定表的路径'</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><p>说明</p>\n<p>1、create table<br />\n 创建一个指定名字的表。如果相同名字的表已经存在，则抛出异常；用户可以用 IF NOT EXISTS 选项来忽略这个异常。</p>\n<p>2、external<br />\n 可以让用户创建一个外部表，在建表的同时指定一个指向实际数据的路径<br />\n (LOCATION),Hive 创建内部表时，会将数据移动到数据仓库指向的路径；若创建外部表，仅记录数据所在的路径，不对数据的位置做任何改变。在删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据</p>\n<p>3、comment<br />\n 表示释，默认不能使用中文</p>\n<p>4、partitioned by<br />\n 表示使用表分区，一个表可以拥有一个或者多个分区，每一个分区单独存在一个目录下</p>\n<p>5、clustered by 对于每一个表分文件，Hive 可以进一步组织成桶，也就是说桶是更为细粒度的数据范围划分。Hive 也是针对某一列进行桶的组织。</p>\n<p>6、sorted by<br />\n 指定排序字段和排序规则</p>\n<p>7、row format<br />\n 指定表文件字段分隔符</p>\n<p>8、stored as 指定表文件的存储格式，常用格式 SEQUENCEFILE,,TEXTFILE, RCFILE, 如果文件数据是纯文本，可以使用 STORED AS TEXTFILE。如果数据需要压缩，使用 stored as<br />\nSEQUENCEFILE。</p>\n<p>9、location<br />\n 指定表文件的存储路径</p>\n<h3 id=\"122建表入门\"><a class=\"anchor\" href=\"#122建表入门\">#</a> 1.2.2 建表入门</h3>\n<p>建表入门</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>use myhive<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>create table stu<span class=\"token punctuation\">(</span>id int,name string<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>insert into stu values<span class=\"token punctuation\">(</span><span class=\"token number\">1</span>,<span class=\"token string\">\"zhangsan\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">#插入数据</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">select</span> * from stu<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>创建表并指定字段之间的分隔符</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>create table <span class=\"token keyword\">if</span> not exists stu2<span class=\"token punctuation\">(</span>id int,name string<span class=\"token punctuation\">)</span> row <span class=\"token function\">format</span> delimited fields terminated by <span class=\"token string\">'it'</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>创建表并指定表文件的存放路径</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>create table <span class=\"token keyword\">if</span> not exists stu2<span class=\"token punctuation\">(</span>id int,name string<span class=\"token punctuation\">)</span> row <span class=\"token function\">format</span> delimited fields terminated by <span class=\"token string\">'<span class=\"token entity\" title=\"\\t\">\\t</span>'</span> location <span class=\"token string\">'/user/stu2'</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>根据查询结果创建表</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>create table stu3 as <span class=\"token keyword\">select</span> * from stu2<span class=\"token punctuation\">;</span> <span class=\"token comment\">#通过复制表结构和表内容创建新表</span></pre></td></tr></table></figure><p>根据已经存在的表结构创建表</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>create table stu4 like stu<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>重询表的详细信息</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>desc formatted stu2<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>删除表</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>drop table stu4<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>加载数据到多分区表中</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>load data <span class=\"token builtin class-name\">local</span> inpath <span class=\"token string\">'/usr/local/src/hivedatas/score.csv'</span> into table</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>score2 partition<span class=\"token punctuation\">(</span>year<span class=\"token operator\">=</span><span class=\"token string\">'2018'</span>, <span class=\"token assign-left variable\">month</span><span class=\"token operator\">=</span><span class=\"token string\">'06'</span>, <span class=\"token assign-left variable\">day</span><span class=\"token operator\">=</span><span class=\"token string\">'01'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>多分区表联合查询使用 (union a11)</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">select</span> * from score where month <span class=\"token operator\">=</span> <span class=\"token string\">'201806'</span> union all <span class=\"token keyword\">select</span> * from score where month <span class=\"token operator\">=</span> <span class=\"token string\">'201806'</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>查看分区</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>show partitions score<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>添加一个分区</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>alter table score <span class=\"token function\">add</span> partition<span class=\"token punctuation\">(</span>month<span class=\"token operator\">=</span><span class=\"token string\">'201805'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>删除分区</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>alter table score drop partition <span class=\"token punctuation\">(</span>month <span class=\"token operator\">=</span><span class=\"token string\">'201806'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>加载数据</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>load data <span class=\"token builtin class-name\">local</span> inpath <span class=\"token string\">'/export/servers/hivedatas/student. csv'</span> into table student<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>加载数据并覆盖已有数据</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>load data <span class=\"token builtin class-name\">local</span> inpath <span class=\"token string\">'/export/servers/hivedatas/student. csv'</span> overwrite into table student<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>从 hdfs 文件系统向表中加载数据 (需要提前将数据上传到 hdfs 文件系统)</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">cd</span> /usr/local/src/hivedatas</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>hdfs dfs -mkdir -p/hivedatas</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>hdfs dfs -put techer.csv /hivedatas/</pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>load data inpath<span class=\"token string\">'/hivedatas/techer.csv'</span> into table teacher<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h2 id=\"13分区表的操作\"><a class=\"anchor\" href=\"#13分区表的操作\">#</a> 1.3. 分区表的操作</h2>\n<p>概念</p>\n<p>在大数据中，最常用的种思想就是分治，可以把大的文件切割划分成一个一个的小的文件，这样每次操作一个小的文件就会很容易了，同样的道理，在 hive 当中也是支持这种思想的，就是我们可以把大的数据，按照每月，或者每天进行切分成一个个的小的文件存放在不同的文件夹中</p>\n<p>创建分区表语法</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>create table score<span class=\"token punctuation\">(</span>s_id string,c-id string,s_score int<span class=\"token punctuation\">)</span> partitioned by <span class=\"token punctuation\">(</span>month string<span class=\"token punctuation\">)</span> row <span class=\"token function\">format</span> delimited fields terminated by <span class=\"token string\">'<span class=\"token entity\" title=\"\\t\">\\t</span>'</span></pre></td></tr></table></figure><p>创建一个表带多个分区</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>create table score2<span class=\"token punctuation\">(</span>s_id string,c_id string, s_score int<span class=\"token punctuation\">)</span> partitioned by</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token punctuation\">(</span>year string, month string, day string<span class=\"token punctuation\">)</span> row <span class=\"token function\">format</span> delimited fields terminated by <span class=\"token string\">'<span class=\"token entity\" title=\"\\t\">\\t</span>'</span></pre></td></tr></table></figure><p>加载数据到分区表中</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>load data <span class=\"token builtin class-name\">local</span> inpath <span class=\"token string\">'/export/servers/hivedatas/score.csv'</span> into table</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>score partition<span class=\"token punctuation\">(</span>month<span class=\"token operator\">=</span><span class=\"token string\">'201806'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h2 id=\"14分桶表操作\"><a class=\"anchor\" href=\"#14分桶表操作\">#</a> 1.4. 分桶表操作</h2>\n<p>概念</p>\n<p>分桶，就是将数据按照指定的字段进行划分到多个文件当中去，分桶就是 MapReduce 中的分区</p>\n<p>开启 Hive 的分桶功能</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">set</span> hive.enforce.bucketing<span class=\"token operator\">=</span>true<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>设置 Reduce 个数</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">set</span> mapreduce.job.reduces<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>创建分桶表</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>create table course <span class=\"token punctuation\">(</span>c_id string, c_name string, t_id string<span class=\"token punctuation\">)</span> clustered by<span class=\"token punctuation\">(</span>c_id<span class=\"token punctuation\">)</span> into <span class=\"token number\">3</span> buckets row <span class=\"token function\">format</span> delimited fields terminated by <span class=\"token string\">'<span class=\"token entity\" title=\"\\t\">\\t</span>'</span></pre></td></tr></table></figure><p>桶表的数据加载，由于通标的数据加载通过 hdfs dfs-put 文件或者通过 load data 均不好使，只能通过 insert overwrite 创建普通表，并通过 insert overwrite 的方式将普通表的数据通过査询的方式加载到桶表当中去</p>\n<p>创建普通表</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>create table course_common<span class=\"token punctuation\">(</span>c_id string, c_name string, t_id string<span class=\"token punctuation\">)</span> row <span class=\"token function\">format</span> delimited fields terminated by <span class=\"token string\">'<span class=\"token entity\" title=\"\\t\">\\t</span>'</span></pre></td></tr></table></figure><p>普通表中加载数据</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>load data <span class=\"token builtin class-name\">local</span> inpath <span class=\"token string\">'/usr/local/src/hivedatas/course.csv'</span> into table</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>course_common<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>通过 insert overwrite 给桶表中加载数据</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>insert overwrite table course <span class=\"token keyword\">select</span> * from course_common cluster by<span class=\"token punctuation\">(</span>c_id<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h2 id=\"15修改表结构\"><a class=\"anchor\" href=\"#15修改表结构\">#</a> 1.5. 修改表结构</h2>\n<p>重命名</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>alter table old_table_name <span class=\"token function\">rename</span> to new_table_name<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>把表 scoe4 修改成 score5</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>alter table score4 <span class=\"token function\">rename</span> to score5<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>增加 / 修改列信息<br />\n查询表结构</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>desc score5<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>添加列</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>alter table score5 <span class=\"token function\">add</span> columns<span class=\"token punctuation\">(</span>mycol string, mysco int<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>更新列</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>alter table score5 change <span class=\"token function\">column</span> mysco mysconew int<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>删除表</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>drop table score5<span class=\"token punctuation\">;</span></pre></td></tr></table></figure>",
            "tags": []
        },
        {
            "id": "https://methiony.work/2020/11/27/Hadoop/Hive/course-5/Hive%E6%A6%82%E8%BF%B0/",
            "url": "https://methiony.work/2020/11/27/Hadoop/Hive/course-5/Hive%E6%A6%82%E8%BF%B0/",
            "title": "Hive概述",
            "date_published": "2020-11-27T14:30:30.000Z",
            "content_html": "<div class=\"note info\">\n<p>以下为个人学习笔记<br />\n课程： 大数据自学教程 Hadoop 从零到精通完整版 @<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vNTg2Mzg5MDQ5\">黑马程序员大数据教程</span><br />\n<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMWVrNHkxMTdZcQ==\"> https://www.bilibili.com/video/BV1ek4y117Yq</span></p>\n</div>\n<h1 id=\"hive概述\"><a class=\"anchor\" href=\"#hive概述\">#</a> Hive 概述</h1>\n<h2 id=\"1数据仓库\"><a class=\"anchor\" href=\"#1数据仓库\">#</a> 1. 数据仓库</h2>\n<h3 id=\"11基本概念\"><a class=\"anchor\" href=\"#11基本概念\">#</a> 1.1 基本概念</h3>\n<p>英文名称为 Data Warehouse, 可简写为 DW 或 DWH。数据仓库的目的是构建面向分析的集成化数据环境，为企业提供决策支持 (Decision Support)。</p>\n<p>数据仓库是存数据的，主要目的是为了分析有效数据，后续会基于它产出供分析挖掘的数据，或者数据应用需要的数据，如企业的分析性报告和各类报表等。<br />\n可以理解为：面向分析的存储系统。</p>\n<h2 id=\"12主要特征\"><a class=\"anchor\" href=\"#12主要特征\">#</a> 1.2 主要特征</h2>\n<p>数据仓库是面向主题的 (Subject-Oriented)、集成的 ( integrated)、非易失的 (Non<br />\nVolatile) 和时变的 (Time-Variant) 数据集合，用以支持管理决策.</p>\n<h3 id=\"121面向主题\"><a class=\"anchor\" href=\"#121面向主题\">#</a> 1.2.1 面向主题</h3>\n<p>数据仓库是面向主题的，数据仓库通过一个个主题域将多个业务系统的数据加载到一起，为了各个主题 (如：用户、订单、商品等) 进行分析而建，操作型数据库是为了支撑各种业务而建立</p>\n<h3 id=\"122集成性\"><a class=\"anchor\" href=\"#122集成性\">#</a> 1.2.2 集成性</h3>\n<p>数据仓库会将不同源数据库中的数据汇总到起，数据仓库中的综合数据不能从原有的数据库<br />\n系统直接得到。因此在数据进入数据仓库之前，必然要经过统一与整合，这一步是据仓库建设中最关键、最复杂的一步 (ET 凵，要统一源数据中所有矛盾之处，如字段的同名义、异名同义、单位不统一、字长不一致，等等</p>\n<h3 id=\"123非易失性\"><a class=\"anchor\" href=\"#123非易失性\">#</a> 1.2.3 非易失性</h3>\n<p>操作型数据库主要服务于日常的业务操作，使得数据库需要不断地对数据实时更新，以便迅速获得当前最新数据，不至于影响正常的业务运作。</p>\n<p>在数据仓库中只要保存过去的业务数据，不需要每一笔业务都实时更新数据仓库，而是根据商业需要毎隔一段时间把一批较新的数据导入数据仓库。数据仓库的数据反映的是一段相当长的时间内历史数据的内容，是不同时点的数据库的集合，以及基于这些快照进行统计、综合和重组的导出数据工数据仓库中的数据一般仅执行査询操作，很少会有删除和更新。但是需定期加载和刷新数据</p>\n<h3 id=\"124时变性\"><a class=\"anchor\" href=\"#124时变性\">#</a> 1.2.4 时变性</h3>\n<p>数据仓库包含各种粒度的历史数据。数据仓库中的数据可能与某个特定日期、星期、月份、季度或者年份有关。数据仓库的目的是通过分析企业过去一段时间业务的经营状况，挖掘其中隐藏的模式。虽然数据仓库的用户不能修改数据，但并不是说数据仓库的数据是永远不变的。分析的结果只能反映过去的情况，当业务变化后，挖掘出的模式会失去时效性。因此数据仓库的数据需要定时更新，以适应决策的需要.</p>\n<h2 id=\"13数据库与数据仓库的区别\"><a class=\"anchor\" href=\"#13数据库与数据仓库的区别\">#</a> 1.3 数据库与数据仓库的区别</h2>\n<p>数据库与数据仓库的区别实际讲的是 0TP 与 OLAP 的区别。</p>\n<p>0TP</p>\n<p>操作型处理，叫联机事务处理 OLTP (On-Line Transaction Processing,), 也可以称面向交易的处理系统，它是针对具体业务在数据库联机的日常操作，通常对少数记录进行査询、修改。用户较为关心操作的响应时间、数据的安全性、完整性和并发支持的用户数等问题。传统的数据库系统作为数据管理的主要手段，主要用于操作型处理。</p>\n<p>OLAP</p>\n<p>分析型处理，叫联机分析处理 OLAP (On-Line Analytical Processing)- 般针对某些主题的历史数据进行分析，支持管理决策。<br />\n首先要明白，数据仓库的出现，并不是要取代数据库<br />\n・数据库是面向事务的设计，数据仓库是面向主题设计的。<br />\n・数据库一般存储业务数据，数据仓库存储的一般是历史数据<br />\n・数据库设计是尽量避免冗余，一般针对某一业务应用进行设计，比如一张简单的 User 表<br />\n记录用户名、密码等简单数据即可，符合业务应用，但是不符合分析。数据仓库在设计是有意引入冗余，依照分析需求，分析维度、分析指标进行设计。<br />\n・数据库是为捕获数据而设计，数据仓库是为分析数据而设计。</p>\n<p>数据仓库，是在数据库已经大量存在的情况下，为了进一步挖掘数据资源、为了决策需要而产生的，它决不是所谓的 “大型数据库”。</p>\n<h2 id=\"14数仓的分层架构\"><a class=\"anchor\" href=\"#14数仓的分层架构\">#</a> 1.4 数仓的分层架构</h2>\n<p>按照数据流入流岀的过程，数据仓库架构可分为三层 -- 源数据、数据仓库、数据应用。</p>\n<p>数据仓库的数据来源于不同的源数据，并提供多样的数据应用，数据自下而上流入数据仓库后向上层开放应用，而数据仓库只是中间集成化数据管理的一个平台。</p>\n<p>源数据层 (DS): 此层数据无任何更改，直接沿用外围系统数据结构和数据，不对外开<br />\n放；为临时存储层，是接口数据的临时存储区域，为后一步的数据处理做准备。</p>\n<p>数据仓库层 (DW): 也称为细节层，DW 层的数据应该是一致的、准确的、干净的数据<br />\n即对源系统数据进行了清洗 (去除了杂质) 后的数据</p>\n<p>数据应用层 (DA 或 APP): 前端应用直接读取的数据源；根据报表、专题分析需求而计算生成的数据。</p>\n<p>数据仓库从各数据源获取数据及在数据仓库内的数据转换和流动都可以认为是 ETL (抽取 Extra, 转化 Transfer, 装载 Load) 的过程，ETL 是数据仓库的流水线，也可以认为是数据仓库的血液，它维系着数据仓库中数据的新陈代谢，而数据仓库曰常的管理和维护工作的大部分精力就是保持 ETL 的正常和稳定</p>\n<h2 id=\"15数仓的元数据管理\"><a class=\"anchor\" href=\"#15数仓的元数据管理\">#</a> 1.5 数仓的元数据管理</h2>\n<p>元数据 (Meta Date), 主要记录数据仓库中模型的定义、各层级间的映射关系、监控数据仓库的数据状态及 ETL 的任务运行状态。一般会通过元数据资料库 ( Metadata Repository) 来统一地存储和管理元数据，其主要目的是使数据仓库的议计、部署、操作和管理能达成协同和一致</p>\n<p>元数据是数据仓库管理系统的重要组成部分，元数据管理是企业级数据仓库中的关键组件，贯穿数据仓库构建的整个过程，直接影响着数据仓库的构建、使用和维护。</p>\n<p>a、构建数据仓库的主要步骤之一是 ETL。这时元数据将发挥重要的作用，它定义了源数据系统到数据仓库的映射、数据转换的规则、数据仓库的逻辑结构、数据更新的规则、数据导入历史记录以及装载周期等相关内容。数据抽取和转换的专家以及数据仓库管理员正是通过元数据高效地构建数据仓库<br />\n b、用户在使用数据仓库时，通过元数据访问数据，明确数据项的含义以及定制报表<br />\n c、数据仓库的规模及其复杂性离不开正确的元数据管理，包括増加或移除外部数据源，改变数据清洗方法，控制岀错的査询以及安排备份等。</p>\n<p>元数据可分为技术元数据和业务元数据</p>\n<h3 id=\"技术元数据\"><a class=\"anchor\" href=\"#技术元数据\">#</a> 技术元数据</h3>\n<p>为开发和管理数据仓库的 T 人员使用，它描述了与数据仓库开发、管理和维护相关的数据，包括数据源信息、数据转换描述、数据仓库模型、数据凊洗与更新规则、数据映射和访问权限等。</p>\n<h3 id=\"业务元数据\"><a class=\"anchor\" href=\"#业务元数据\">#</a> 业务元数据</h3>\n<p>为管理层和业务分析人员服务，从业务角度描述数据，包括商务术语、数据仓库中有什么数据、数据的位置和数据的可用性等，帮助业务人员更好地理解数据仓库中哪些数据是可用的以及如何使用。</p>\n<p>由上可见，元数据不仅定义了数据仓库中数据的模式、来源、抽取和转换规则等，而且是整个数据仓库系统运行的基础，元数据把数据仓库系统中各个松散的组件联系起来，组成了一个有机的整体</p>\n",
            "tags": []
        }
    ]
}