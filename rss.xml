<?xml version="1.0"?>
<rss version="2.0">
    <channel>
        <title>Andrésen</title>
        <link>https://methiony.work</link>
        <description></description>
        <language>zh-CN</language>
        <pubDate>Sat, 21 Nov 2020 18:41:39 +0800</pubDate>
        <lastBuildDate>Sat, 21 Nov 2020 18:41:39 +0800</lastBuildDate>
        <item>
            <guid isPermalink="true">https://methiony.work/2020/11/21/Hadoop%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</guid>
            <title></title>
            <link>https://methiony.work/2020/11/21/Hadoop%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</link>
            <pubDate>Sat, 21 Nov 2020 18:41:39 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;title: Zookeeper 基础知识&lt;br /&gt;
 date: 2020-11-21 17:40:19&lt;br /&gt;
tags:&lt;/p&gt;
&lt;h1 id=&#34;hadoop分布式集群搭建&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#hadoop分布式集群搭建&#34;&gt;#&lt;/a&gt; Hadoop 分布式集群搭建&lt;/h1&gt;
&lt;h2 id=&#34;1-环境准备&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-环境准备&#34;&gt;#&lt;/a&gt; 1、环境准备&lt;/h2&gt;
&lt;p&gt;首先准备了三台虚拟机（为了避免环境的干扰，都是新建的虚拟机），分别分配了 1G 内存、20G 硬盘、2 核 CPU，然后安装了 CentOS-7-x86_64-DVD-2009 操作系统，并配置了静态 IP 地址。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;集群规划：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;搭建的是 NameNode 与 ResourceManager 单节点架构。节点具体分别如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;服务器名称&lt;/th&gt;
&lt;th&gt;IP 地址&lt;/th&gt;
&lt;th&gt;NameNode&lt;/th&gt;
&lt;th&gt;SecondaryNameNode&lt;/th&gt;
&lt;th&gt;dataNode&lt;/th&gt;
&lt;th&gt;ResourceManager&lt;/th&gt;
&lt;th&gt;NodeManager&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;master&lt;/td&gt;
&lt;td&gt;192.168.2.128&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;node01&lt;/td&gt;
&lt;td&gt;192.168.2.129&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;node02&lt;/td&gt;
&lt;td&gt;192.168.2.130&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;文件系统核心模块：&lt;/strong&gt;&lt;br /&gt;
NameNode：集群当中的主节点，主要用于管理集群当中的各种数据&lt;br /&gt;
 secondaryNameNode：主要能用于 hadoop 当中元数据信息的辅助管理&lt;br /&gt;
 DataNode：集群当中的从节点，主要用于存储集群当中的各种数据&lt;br /&gt;
&lt;strong&gt;数据计算核心模块：&lt;/strong&gt;&lt;br /&gt;
ResourceManager：接收用户的计算请求任务，并负责集群的资源分配&lt;br /&gt;
 NodeManager：负责执行主节点 APPmaster 分配的任务&lt;/p&gt;
&lt;h2 id=&#34;2-环境配置&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-环境配置&#34;&gt;#&lt;/a&gt; 2、环境配置&lt;/h2&gt;
&lt;p&gt;1、关闭防火墙&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@localhost ~]# systemctl stop firewalld.service 
#关闭防火墙
[root@localhost ~]# systemctl disable firewalld.service 
#禁止开机启动
[root@localhost ~]*# firewall-cmd --state 
#查看防火墙状态
not running
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;2、设置主机名称&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#在192.168.2.128机器上执行* 
[root@localhost ~]*# hostnamectl set-hostname  master

*#在192.168.2.129机器上执行* 
[root@localhost ~]*# hostnamectl set-hostname node01

*#在192.168.2.130机器上执行* 
[root@localhost ~]*# hostnamectl set-hostname node02
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;3、三台虚拟机重启&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#在192.168.2.128机器上执行* 
[root@localhost ~]# reboot

*#在192.168.2.129机器上执行* 
[root@localhost ~]# reboot

*#在192.168.2.130机器上执行* 
[root@localhost ~]# reboot
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;4、关闭 selinux&lt;/p&gt;
&lt;p&gt;进入到 /etc/selinux/config 文件，将 SELINUX=enforcing 改为 SELINUX=disabled。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@master ~]#  vi  /etc/selinux/config
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;5、设置免密登录&lt;/p&gt;
&lt;p&gt;首先在 master 主机上使用 ssh-keygen 命令来生成秘钥，一路按回车键&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@master~]#ssh-keygen -t rsa
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;通过 ssh-copy-id 命令设置免密钥登录&lt;br /&gt;
其中，master、node01、node02 表示需要设置免密登录的服务器地址。&lt;/p&gt;
&lt;figure class=&#34;highlight powershell&#34;&gt;&lt;figcaption data-lang=&#34;PowerShell&#34;&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td data-num=&#34;1&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;ssh&lt;span class=&#34;token operator&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;token function&#34;&gt;copy-id&lt;/span&gt; &lt;span class=&#34;token operator&#34;&gt;-&lt;/span&gt;i ~&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;ssh&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;id_rsa&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;pub root@192&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;168&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;2&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;128&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;2&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;ssh&lt;span class=&#34;token operator&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;token function&#34;&gt;copy-id&lt;/span&gt; &lt;span class=&#34;token operator&#34;&gt;-&lt;/span&gt;i ~&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;ssh&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;id_rsa&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;pub root@192&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;168&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;2&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;129&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;3&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;ssh&lt;span class=&#34;token operator&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;token function&#34;&gt;copy-id&lt;/span&gt; &lt;span class=&#34;token operator&#34;&gt;-&lt;/span&gt;i ~&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;ssh&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;id_rsa&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;pub root@192&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;168&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;2&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;130&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h2 id=&#34;3-安装jdk&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-安装jdk&#34;&gt;#&lt;/a&gt; 3、安装 JDK&lt;/h2&gt;
&lt;p&gt;在 master 中新建目录 /opt/bigdata/, 此目录下存放 hadoop 大数据所需要的环境包 (jdk 和 hadoop).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@master~]#mkdir /opt/bigdata
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;1、把下载好的 jdk-8u271-linux-x64.tar.gz 包和 hadoop-3.1.4.tar.gz 上传至 master 主机中，JDK 是安装 Hadoop 的基础环境，所以需要优先安装好 JDK 环境&lt;/p&gt;
&lt;p&gt;2、解压 jdk 并复制到 /opt/bigdata 目录下&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@master~]#tar -zxvf jdk-8u271-linux-x64.tar.gz -C
/opt/bigdata
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;3、配置环境变量 (/etc/profile)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@master~]#vi /etc/profile
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;添加&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export JAVA_HOME=/export/servers/jdk1.8.0_271 
export PATH=:$JAVA_HOME/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;执行下面命令，让环境变量生效&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@master~]#source/etc/profile
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;验证 jdk 安装是否成功&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@master~]#java -version
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;4-安装hadoop&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4-安装hadoop&#34;&gt;#&lt;/a&gt; 4、安装 hadoop&lt;/h2&gt;
&lt;p&gt;1、解压 hadoop，并把解压文件复制到 /opt/bigdata 目录中&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@master~]#tar -zxvf hadoop-3.1.4.tar.gz -C /opt/bigdata
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;2、配置环境变量 (/etc/profile)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@master~]#vi /etc/profile
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;添加&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export HADOOP_HOME=/export/servers/hadoop-3.1.4
export PATH=:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;执行下面命令，让环境变量生效&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@master~]#source/etc/profile
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;3、修改 hadoop 的配置文件&lt;/p&gt;
&lt;p&gt;进入需改文件的目录&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@master~]#cd /opt/bigdata/hadoop-3.1.4/etc/hadoop
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;需要修改的文件&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;core-site.xml	hadoop-env.sh	hdfs-site.xml	
mapred-env.sh	mapred-site.xml	yarn-site.xml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;首先，修改 core-site.xml 文件，在 &amp;lt;configuration&amp;gt; 元素中添加相应的配置文件&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;configuration&amp;gt; 	
	&amp;lt;!--  指定集群的文件系统类型:分布式文件系统 --&amp;gt; 	
	&amp;lt;property&amp;gt; 		
		&amp;lt;name&amp;gt;fs.default.name&amp;lt;/name&amp;gt; 		
	&amp;lt;!--因为前面已经配置了服务器名称映射IP，所以这里可以使用服务器名称进行配置--&amp;gt; 		
		&amp;lt;value&amp;gt;hdfs://master:8020&amp;lt;/value&amp;gt; 	
	&amp;lt;/property&amp;gt; 
	&amp;lt;!--  指定临时文件存储目录 --&amp;gt; 	
	&amp;lt;property&amp;gt; 
		&amp;lt;name&amp;gt;hadoop.tmp.dir&amp;lt;/name&amp;gt; 					     &amp;lt;value&amp;gt;/opt/bigdata/hadoop3.1.4/hadoopDatas/tempDatas&amp;lt;/value&amp;gt; 	
	&amp;lt;/property&amp;gt;
	&amp;lt;!--  缓冲区大小，实际工作中根据服务器性能动态调整 --&amp;gt; 	
	&amp;lt;property&amp;gt; 		
		&amp;lt;name&amp;gt;io.file.buffer.size&amp;lt;/name&amp;gt; 		
		&amp;lt;value&amp;gt;4096&amp;lt;/value&amp;gt; 	
	&amp;lt;/property&amp;gt;  	
	&amp;lt;!--  开启hdfs的垃圾桶机制，删除掉的数据可以从垃圾桶中回收，单位分钟 --&amp;gt; 	
	&amp;lt;property&amp;gt; 
		&amp;lt;name&amp;gt;fs.trash.interval&amp;lt;/name&amp;gt; 
		&amp;lt;value&amp;gt;10080&amp;lt;/value&amp;gt; 	
	&amp;lt;/property&amp;gt; 
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其次，修改 hdfs-site.xml 文件，在 &amp;lt;configuration&amp;gt; 元素中添加相应的配置文件&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;configuration&amp;gt;
	 &amp;lt;property&amp;gt;
			&amp;lt;name&amp;gt;dfs.namenode.secondary.http-address&amp;lt;/name&amp;gt;
			&amp;lt;value&amp;gt;master:50090&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;

	&amp;lt;!-- 指定namenode的访问地址和端口 --&amp;gt;
	&amp;lt;property&amp;gt;
		&amp;lt;name&amp;gt;dfs.namenode.http-address&amp;lt;/name&amp;gt;
		&amp;lt;value&amp;gt;master:50070&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
	&amp;lt;!-- 指定namenode元数据的存放位置 --&amp;gt;
	&amp;lt;property&amp;gt;
		&amp;lt;name&amp;gt;dfs.namenode.name.dir&amp;lt;/name&amp;gt;
		&amp;lt;value&amp;gt;file:///opt/bigdata/hadoop-3.1.4/hadoopDatas/namenodeDatas,file:///opt/bigdata/hadoop-3.1.4/hadoopDatas/namenodeDatas2&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
	&amp;lt;!--  定义dataNode数据存储的节点位置，实际工作中，一般先确定磁盘的挂载目录，然后多个目录用，进行分割  --&amp;gt;
	&amp;lt;property&amp;gt;
		&amp;lt;name&amp;gt;dfs.datanode.data.dir&amp;lt;/name&amp;gt;
		&amp;lt;value&amp;gt;file:///opt/bigdata/hadoop-3.1.4/hadoopDatas/datanodeDatas,file:///opt/bigdata/hadoop-3.1.4/hadoopDatas/datanodeDatas2&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
	
	&amp;lt;!-- 指定namenode日志文件的存放目录 --&amp;gt;
	&amp;lt;property&amp;gt;
		&amp;lt;name&amp;gt;dfs.namenode.edits.dir&amp;lt;/name&amp;gt;
		&amp;lt;value&amp;gt;file:///opt/bigdata/hadoop-3.1.4/hadoopDatas/nn/edits&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
	&amp;lt;property&amp;gt;
		&amp;lt;name&amp;gt;dfs.namenode.checkpoint.dir&amp;lt;/name&amp;gt;
		&amp;lt;value&amp;gt;file:///opt/bigdata/hadoop-3.1.4/hadoopDatas/snn/name&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
	&amp;lt;property&amp;gt;
		&amp;lt;name&amp;gt;dfs.namenode.checkpoint.edits.dir&amp;lt;/name&amp;gt;
		&amp;lt;value&amp;gt;file:///opt/bigdata/hadoop-3.1.4/hadoopDatas/dfs/snn/edits&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
	&amp;lt;!-- 文件切片的副本个数--&amp;gt;
	&amp;lt;property&amp;gt;
		&amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
		&amp;lt;value&amp;gt;3&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;

	&amp;lt;!-- 设置HDFS的文件权限--&amp;gt;
	&amp;lt;property&amp;gt;
		&amp;lt;name&amp;gt;dfs.permissions&amp;lt;/name&amp;gt;
		&amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;

	&amp;lt;!-- 设置一个文件切片的大小：128M--&amp;gt;
	&amp;lt;property&amp;gt;
		&amp;lt;name&amp;gt;dfs.blocksize&amp;lt;/name&amp;gt;
		&amp;lt;value&amp;gt;134217728&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然后，修改 yarn-site.xml 文件，在 &amp;lt;configuration&amp;gt; 元素中添加相应的配置文件&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;configuration&amp;gt;
	&amp;lt;!-- 配置yarn主节点的位置 --&amp;gt;
	&amp;lt;property&amp;gt;
		&amp;lt;name&amp;gt;yarn.resourcemanager.hostname&amp;lt;/name&amp;gt;
		&amp;lt;value&amp;gt;master&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
	&amp;lt;property&amp;gt;
		&amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;
		&amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
	
	&amp;lt;!-- 开启日志聚合功能 --&amp;gt;
	&amp;lt;property&amp;gt;
		&amp;lt;name&amp;gt;yarn.log-aggregation-enable&amp;lt;/name&amp;gt;
		&amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
	&amp;lt;!-- 设置聚合日志在hdfs上的保存时间 --&amp;gt;
	&amp;lt;property&amp;gt;
		&amp;lt;name&amp;gt;yarn.log-aggregation.retain-seconds&amp;lt;/name&amp;gt;
		&amp;lt;value&amp;gt;604800&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
	&amp;lt;!-- 设置yarn集群的内存分配方案 --&amp;gt;
	&amp;lt;property&amp;gt;    
		&amp;lt;name&amp;gt;yarn.nodemanager.resource.memory-mb&amp;lt;/name&amp;gt;    
		&amp;lt;value&amp;gt;20480&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;

	&amp;lt;property&amp;gt;  
        	 &amp;lt;name&amp;gt;yarn.scheduler.minimum-allocation-mb&amp;lt;/name&amp;gt;
         	&amp;lt;value&amp;gt;2048&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
	&amp;lt;property&amp;gt;
		&amp;lt;name&amp;gt;yarn.nodemanager.vmem-pmem-ratio&amp;lt;/name&amp;gt;
		&amp;lt;value&amp;gt;2.1&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;

&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然后，修改 mapred-site.xml 文件，在 &amp;lt;configuration&amp;gt; 元素中添加相应的配置文件&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;configuration&amp;gt;
	&amp;lt;!-- 开启MapReduce小任务模式 --&amp;gt;
	&amp;lt;property&amp;gt;
		&amp;lt;name&amp;gt;mapreduce.job.ubertask.enable&amp;lt;/name&amp;gt;
		&amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
	
	&amp;lt;!-- 设置历史任务的主机和端口 --&amp;gt;
	&amp;lt;property&amp;gt;
		&amp;lt;name&amp;gt;mapreduce.jobhistory.address&amp;lt;/name&amp;gt;
		&amp;lt;value&amp;gt;master:10020&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;

	&amp;lt;!-- 设置网页访问历史任务的主机和端口 --&amp;gt;
	&amp;lt;property&amp;gt;
		&amp;lt;name&amp;gt;mapreduce.jobhistory.webapp.address&amp;lt;/name&amp;gt;
		&amp;lt;value&amp;gt;master:19888&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然后，&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cDovL3huLS1oYWRvb3AtZW52LXl1NnA1NHIwbmE1NjF0LnNo&#34;&gt;分别修改 hadoop-env.sh&lt;/span&gt;、mapred-env.sh 文件&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@master hadoop]#vi hadoop-env.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[root@master hadoop]#vi mapred-env.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;添加 Java 环境变量&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export JAVA_HOME=/opt/bigdata/jdk1.8.0_271
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;最后，修改集群配置文件 slaves（没有则新建）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@master hadoop]#vi slaves
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;添加&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;master
node01
node02
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;4、创建 hadoop 需要的文件目录&lt;/p&gt;
&lt;figure class=&#34;highlight powershell&#34;&gt;&lt;figcaption data-lang=&#34;PowerShell&#34;&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td data-num=&#34;1&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;mkdir &lt;span class=&#34;token operator&#34;&gt;-&lt;/span&gt;p &lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;opt&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;bigdata&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;hadoop&lt;span class=&#34;token operator&#34;&gt;-&lt;/span&gt;3&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;1&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;4&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;hadoopDatas&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;tempDatas&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;2&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;mkdir &lt;span class=&#34;token operator&#34;&gt;-&lt;/span&gt;p &lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;opt&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;bigdata&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;hadoop&lt;span class=&#34;token operator&#34;&gt;-&lt;/span&gt;3&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;1&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;4&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;hadoopDatas&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;namenodeDatas&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;3&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;4&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;mkdir &lt;span class=&#34;token operator&#34;&gt;-&lt;/span&gt;p &lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;opt&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;bigdata&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;hadoop&lt;span class=&#34;token operator&#34;&gt;-&lt;/span&gt;3&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;1&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;4&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;hadoopDatas&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;namenodeDatas2&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;5&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;6&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;mkdir &lt;span class=&#34;token operator&#34;&gt;-&lt;/span&gt;p &lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;opt&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;bigdata&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;hadoop&lt;span class=&#34;token operator&#34;&gt;-&lt;/span&gt;3&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;1&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;4&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;hadoopDatas&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;datanodeDatas&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;7&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;8&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;mkdir &lt;span class=&#34;token operator&#34;&gt;-&lt;/span&gt;p &lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;opt&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;bigdata&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;hadoop&lt;span class=&#34;token operator&#34;&gt;-&lt;/span&gt;3&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;1&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;4&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;hadoopDatas&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;datanodeDatas2 &lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;9&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;10&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;mkdir &lt;span class=&#34;token operator&#34;&gt;-&lt;/span&gt;p &lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;opt&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;bigdata&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;hadoop&lt;span class=&#34;token operator&#34;&gt;-&lt;/span&gt;3&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;1&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;4&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;hadoopDatas&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;nn&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;edits&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;11&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;mkdir &lt;span class=&#34;token operator&#34;&gt;-&lt;/span&gt;p &lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;opt&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;bigdata&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;hadoop&lt;span class=&#34;token operator&#34;&gt;-&lt;/span&gt;3&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;1&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;4&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;hadoopDatas&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;snn&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;name&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;12&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;mkdir &lt;span class=&#34;token operator&#34;&gt;-&lt;/span&gt;p &lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;opt&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;bigdata&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;hadoop&lt;span class=&#34;token operator&#34;&gt;-&lt;/span&gt;3&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;1&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;4&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;hadoopDatas&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;dfs&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;snn&lt;span class=&#34;token operator&#34;&gt;/&lt;/span&gt;edits&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h2 id=&#34;5-分发jdk-hadoop到node01-node02&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#5-分发jdk-hadoop到node01-node02&#34;&gt;#&lt;/a&gt; 5、分发 jdk、hadoop 到 node01、node02&lt;/h2&gt;
&lt;p&gt;首先进入 jdk、hadoop 的安装目录&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@master hadoop]#cd /opt/bigdata
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然后分发 jdk，分别到 node01、node02&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;scp -r jdk1.8.0_271 node01:$PWD 
scp -r jdk1.8.0_271 node02:$PWD
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;分发 Hadoop，分别到 node01、node02&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;scp -r hadoop-3.1.4 node01:$PWD 
scp -r hadoop-3.1.4 node02:$PWD
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;分发 master 已经配置好的环境变量文件到 node01、node02 (需要进入到根目录)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;scp -r /etc/profile root@node01:/etc/profile 
scp -r /etc/profile root@node02:/etc/profile
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;执行下面命令，让环境变量生效&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node01~]#source/etc/profile
[root@node02~]#source/etc/profile
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;检查是否生效&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node01~]#java -version
[root@node02~]#java -version
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;6-启动集群&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#6-启动集群&#34;&gt;#&lt;/a&gt; 6、启动集群&lt;/h2&gt;
&lt;p&gt;首先，在 master 主机进行格式化（首次需要执行）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd  /opt/bigdata/hadoop-3.1.4/ #首先进入hadoop根目录
bin/hdfs namenode -format #执行格式化命令
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然后，启动 hdfs 集群&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sbin/start-dfs.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;再启动 yarn 集群&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sbin/start-yarn.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;最后，启动 historyserver，查看历史完成的任务&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sbin/mr-jobhistory-daemon.sh start historyserver
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用 jps 查看进程&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@master~]#jps
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;7-查看可视化界面验证启动是否成功&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#7-查看可视化界面验证启动是否成功&#34;&gt;#&lt;/a&gt; 7、查看可视化界面，验证启动是否成功&lt;/h2&gt;
&lt;p&gt;1、首先访问：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cDovLzE5Mi4xNjguMi4xMjg6NTAwNzAvZXhwbG9yZXIuaHRtbCMvJUVGJUJDJThDJUU3JTk0JUE4JUU2JTlEJUE1JUU2JTlGJUE1JUU3JTlDJThCaGRmcw==&#34;&gt;http://192.168.2.128:50070/explorer.html#/，用来查看 hdfs&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;2、然后访问：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cDovLzE5Mi4xNjguMi4xMjg6ODA4OC9jbHVzdGVyJUVGJUJDJThDJUU2JTlGJUE1JUU3JTlDJThCeWFybiVFOSU5QiU4NiVFNyVCRSVBNA==&#34;&gt;http://192.168.2.128:8088/cluster，查看 yarn 集群&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;3、最后访问：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cDovLzE5Mi4xNjguMi4xMjg6MTk4ODgvam9iaGlzdG9yeSVFRiVCQyU4QyVFNiU5RiVBNSVFNyU5QyU4QiVFNSU4RSU4NiVFNSU4RiVCMiVFNSVBRSU4QyVFNiU4OCU5MCVFNyU5QSU4NCVFNCVCQiVCQiVFNSU4QSVBMQ==&#34;&gt;http://192.168.2.128:19888/jobhistory，查看历史完成的任务&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如果都有页面表示搭建成功！&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://methiony.work/2020/11/21/Zookeeper%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</guid>
            <title>Zookeeper基础知识</title>
            <link>https://methiony.work/2020/11/21/Zookeeper%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</link>
            <pubDate>Sat, 21 Nov 2020 17:40:19 +0800</pubDate>
            <description><![CDATA[  ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://methiony.work/2020/11/19/Hbase/</guid>
            <title>Hbase</title>
            <link>https://methiony.work/2020/11/19/Hbase/</link>
            <pubDate>Thu, 19 Nov 2020 15:53:18 +0800</pubDate>
            <description><![CDATA[ &lt;h1 id=&#34;hbase基础系列1&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#hbase基础系列1&#34;&gt;#&lt;/a&gt; Hbase 基础系列（1）&lt;/h1&gt;
&lt;h2 id=&#34;1-hbase定义&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-hbase定义&#34;&gt;#&lt;/a&gt; 1、 HBase 定义&lt;/h2&gt;
&lt;p&gt;HBase 是一种分布式、可扩展、支持海量数据存储的 NoSQL 数据库。&lt;/p&gt;
&lt;h2 id=&#34;2-hbase特点&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-hbase特点&#34;&gt;#&lt;/a&gt; 2、HBase 特点&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;1. 海量存储&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hbase 适合存储 PB 级别的海量数据，在 PB 级别的数据以及采用廉价 PC 存储的情况下，能在几十到百毫秒内返回数据。这与 Hbase 的极易扩展性息息相关。正式因为 Hbase 良好的扩展性，才为海量数据的存储提供了便利。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2. 列式存储&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里的列式存储其实说的是列族存储，Hbase 是根据列族来存储数据的。列族下面可以有非常多的列，列族在创建表的时候就必须指定。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;3. 极易扩展&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hbase 的扩展性主要体现在两个方面，一个是基于上层处理能力（RegionServer）的扩展，一个是基于存储的扩展（HDFS）。&lt;br /&gt;
通过横向添加 RegionSever 的机器，进行水平扩展，提升 Hbase 上层的处理能力，提升 Hbsae 服务更多 Region 的能力。&lt;br /&gt;
  备注：RegionServer 的作用是管理 region、承接业务的访问，这个后面会详细的介绍通过横向添加 Datanode 的机器，进行存储层扩容，提升 Hbase 的数据存储能力和提升后端存储的读写能力。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;4. 高并发&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于目前大部分使用 Hbase 的架构，都是采用的廉价 PC，因此单个 IO 的延迟其实并不小，一般在几十到上百 ms 之间。这里说的高并发，主要是在并发的情况下，Hbase 的单个 IO 延迟下降并不多。能获得高并发、低延迟的服务。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;5. 稀疏&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;稀疏主要是针对 Hbase 列的灵活性，在列族中，你可以指定任意多的列，在列数据为空的情况下，是不会占用存储空间的。&lt;/p&gt;
&lt;h2 id=&#34;3-hbase的数据模型&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-hbase的数据模型&#34;&gt;#&lt;/a&gt; 3、Hbase 的数据模型&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cDovLzEuTmFtZQ==&#34;&gt;1.Name&lt;/span&gt; Space&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;命名空间，类似于关系型数据库的 database 概念，每个命名空间下有多个表。HBase 两个自带的命名空间，分别是 hbase 和 default，hbase 中存放的是 HBase 内置的表，default 表是用户默认使用的命名空间。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2.Table&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;类似于关系型数据库的表概念。不同的是，HBase 定义表时只需要声明列族即可，不需要声明具体的列。这意味着，往 HBase 写入数据时，字段可以动态、按需指定。因此，和关系型数据库相比，HBase 能够轻松应对字段变更的场景。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;3.Row&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;HBase 表中的每行数据都由一个 RowKey 和多个 Column（列）组成，数据是按照 RowKey 的字典顺序存储的，并且查询数据时只能根据 RowKey 进行检索，所以 RowKey 的设计十分重要。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;4.Column&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;HBase 中的每个列都由 Column Family (列族) 和 Column Qualifier（列限定符）进行限定，例如 info：name，info：age。建表时，只需指明列族，而列限定符无需预先定义。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;5.Time Stamp&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用于标识数据的不同版本（version），每条数据写入时，系统会自动为其加上该字段，其值为写入 HBase 的时间。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;6.Cell&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由 {rowkey, column Family：column Qualifier, time Stamp} 唯一确定的单元。cell 中的数据是没有类型的，全部是字节码形式存贮。&lt;/p&gt;
&lt;h2 id=&#34;4-hbase架构&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4-hbase架构&#34;&gt;#&lt;/a&gt; 4、 HBase 架构&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;1.Client&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Client 包含了访问 Hbase 的接口，另外 Client 还维护了对应的 cache 来加速 Hbase 的访问，比如 cache 的.META. 元数据的信息。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2.Zookeeper&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;HBase 通过 Zookeeper 来做 master 的高可用、RegionServer 的监控、元数据的入口以及集群配置的维护等工作。具体工作如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;通过 Zoopkeeper 来保证集群中只有 1 个 master 在运行，如果 master 异常，会通过竞争机制产生新的 master 提供服务&lt;br /&gt;
通过 Zoopkeeper 来监控 RegionServer 的状态，当 RegionSevrer 有异常的时候，通过回调的形式通知 MasterRegionServer 上下线的信息&lt;br /&gt;
通过 Zoopkeeper 存储元数据的统一入口地址&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;3.Hmaster&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;master 节点的主要职责如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;为 RegionServer 分配 Region&lt;br /&gt;
 维护整个集群的负载均衡&lt;br /&gt;
维护集群的元数据信息&lt;br /&gt;
发现失效的 Region，并将失效的 Region 分配到正常的 RegionServer 上&lt;br /&gt;
当 RegionSever 失效的时候，协调对应 Hlog 的拆分&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;4.HregionServer&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;HregionServer 直接对接用户的读写请求，是真正的 “干活” 的节点。它的功能概括如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;管理 master 为其分配的 Region&lt;br /&gt;
 处理来自客户端的读写请求&lt;br /&gt;
负责和底层 HDFS 的交互，&lt;br /&gt;
存储数据到 HDFS&lt;br /&gt;
 负责 Region 变大以后的拆分&lt;br /&gt;
负责 Storefile 的合并工作&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;5.HDFS&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;HDFS 为 Hbase 提供最终的底层数据存储服务，同时为 HBase 提供高可用（Hlog 存储在 HDFS）的支持，具体功能概括如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;提供元数据和表数据的底层分布式存储服务&lt;br /&gt;
数据多副本，保证的高可靠和高可用性&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;5-hbase中的角色&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#5-hbase中的角色&#34;&gt;#&lt;/a&gt; 5、HBase 中的角色&lt;/h2&gt;
&lt;h4 id=&#34;1-hmaster&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-hmaster&#34;&gt;#&lt;/a&gt; 1 HMaster&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;功能&lt;/li&gt;
&lt;li&gt;1．监控 RegionServer&lt;/li&gt;
&lt;li&gt;2．处理 RegionServer 故障转移&lt;/li&gt;
&lt;li&gt;3．处理元数据的变更&lt;/li&gt;
&lt;li&gt;4．处理 region 的分配或转移&lt;/li&gt;
&lt;li&gt;5．在空闲时间进行数据的负载均衡&lt;/li&gt;
&lt;li&gt;6．通过 Zookeeper 发布自己的位置给客户端&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2-regionserver&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-regionserver&#34;&gt;#&lt;/a&gt; 2 RegionServer&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;功能&lt;/li&gt;
&lt;li&gt;1．负责存储 HBase 的实际数据&lt;/li&gt;
&lt;li&gt;2．处理分配给它的 Region&lt;/li&gt;
&lt;li&gt;3．刷新缓存到 HDFS&lt;/li&gt;
&lt;li&gt;4．维护 Hlog&lt;/li&gt;
&lt;li&gt;5．执行压缩&lt;/li&gt;
&lt;li&gt;6．负责处理 Region 分片&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;3-其他组件&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-其他组件&#34;&gt;#&lt;/a&gt; 3. 其他组件&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;1．Write-Ahead logs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;HBase 的修改记录，当对 HBase 读写数据的时候，数据不是直接写进磁盘，它会在内存中保留一段时间（时间以及数据量阈值可以设定）。但把数据保存在内存中可能有更高的概率引起数据丢失，为了解决这个问题，数据会先写在一个叫做 Write-Ahead logfile 的文件中，然后再写入内存中。所以在系统出现故障的时候，数据可以通过这个日志文件重建。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2．Region&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hbase 表的分片，HBase 表会根据 RowKey 值被切分成不同的 region 存储在 RegionServer 中，在一个 RegionServer 中可以有多个不同的 region。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;3．Store&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;HFile 存储在 Store 中，一个 Store 对应 HBase 表中的一个列族。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;4．MemStore&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;顾名思义，就是内存存储，位于内存中，用来保存当前的数据操作，所以当数据保存在 WAL 中之后，RegsionServer 会在内存中存储键值对。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;5．HFile&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这是在磁盘上保存原始数据的实际的物理文件，是实际的存储文件。StoreFile 是以 Hfile 的形式存储在 HDFS 的。&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://methiony.work/2020/11/15/MySQL-0/</guid>
            <title>MySQL</title>
            <link>https://methiony.work/2020/11/15/MySQL-0/</link>
            <pubDate>Sun, 15 Nov 2020 18:43:49 +0800</pubDate>
            <description><![CDATA[ &lt;h2 id=&#34;mysql服务的登录和退出&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#mysql服务的登录和退出&#34;&gt;#&lt;/a&gt; MySql 服务的登录和退出&lt;/h2&gt;
&lt;p&gt;​		方式一：通过 mysql 自带的客户端：只限于 root 用户&lt;/p&gt;
&lt;p&gt;​		方式二：通过 Windows 自带的客户端：1、登录：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql	[-h主机名	-p端口号]	-u用户名	-p 密码
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;​		退出：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;exit或ctrl + c
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;mysql的常见命令&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#mysql的常见命令&#34;&gt;#&lt;/a&gt; MySql 的常见命令&lt;/h2&gt;
&lt;p&gt;​		1、查看当前所有的数据库：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;show	databases;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;​		2、打开指定的库：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;use	库名
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;​		3、查看当前库的所有表：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;show	tables;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;​		4、查看其他库的所有表：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;show	tables	from	库名;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;​		5、创建表：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;create	table	表名(

​						列名	列类型,

​						列名	列类型,

​						...

​			)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;​		6、查看表结构：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;desc	表名;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;​		7、查看服务器的版本&lt;/p&gt;
&lt;p&gt;​			方式一、登录到 mysql 服务端:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select	version();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;​			方式二、没有登录到 mysql 服务端:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql	--version或	mysql	--v
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;进阶1基础查询&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#进阶1基础查询&#34;&gt;#&lt;/a&gt; 进阶 1：基础查询&lt;/h3&gt;
&lt;p&gt;语法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select	查询列表	from	表名;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;特点：&lt;/p&gt;
&lt;p&gt;1、查询列表可以是：表中的字段、常量值、表达式、函数&lt;/p&gt;
&lt;p&gt;2、查询的结果是一个虚拟的表格&lt;/p&gt;
&lt;p&gt;a、查询表中的单个字段：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select	查询列表	from	表名;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;b、查询表中的多个字段：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select	查询列表1,查询列表2,...	from	表名;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;c、查询表中的所有字段：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select	*	from	表名;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;d、查询常量值：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select	100;	select	&#39;john&#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;e、查询表达式：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select	100%98;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;f、查询函数：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select	version();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;3、起别名：便于理解、如果查询的字段有重名的情况，使用别名区分&lt;/p&gt;
&lt;p&gt;a、使用 as&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select	100%98	as	结果;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;select	查询列表1 as 别名,查询列表2 as 别名	from	表名;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;b、使用空格&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select	查询列表1  别名,查询列表2  别名	from	表名;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;4、去重&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select	distinct	查询列表	from	表名;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;进阶2条件查询&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#进阶2条件查询&#34;&gt;#&lt;/a&gt; 进阶 2：条件查询&lt;/h3&gt;
&lt;p&gt;语法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select	查询列表	from	表名	where	筛选条件;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;分类：&lt;/p&gt;
&lt;p&gt;一、按条件表达式筛选&lt;/p&gt;
&lt;p&gt;简单条件运算符：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;	&amp;lt;	=	!=	&amp;lt;&amp;gt;	&amp;gt;=	&amp;lt;=
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;二、按逻辑表达式筛选&lt;/p&gt;
&lt;p&gt;逻辑运算符：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;amp;&amp;amp;	||	！	and	or	not
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;三、模糊查询&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;like	between	and	in	is	null
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;mysql的语法规范&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#mysql的语法规范&#34;&gt;#&lt;/a&gt; Mysql 的语法规范&lt;/h2&gt;
&lt;p&gt;​			1、不区分大小写，但建议关键词大写，表名、列名小写&lt;/p&gt;
&lt;p&gt;​			2、每条命令最好用分号结尾&lt;/p&gt;
&lt;p&gt;​			3、每条命令根据需要，可以进行缩进或换行&lt;/p&gt;
&lt;p&gt;​			4、注释：a、单行注释：# 注释文字	b、单行注释：-- 注释文字	c、单行注释：/ *   注释文字   */&lt;/p&gt;
&lt;p&gt;​			5、mysql 中的 + 号：只有作为运算符的功能&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://methiony.work/2020/11/06/hello-world/</guid>
            <title>Hello World</title>
            <link>https://methiony.work/2020/11/06/hello-world/</link>
            <pubDate>Fri, 06 Nov 2020 08:20:44 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;Welcome to &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9oZXhvLmlvLw==&#34;&gt;Hexo&lt;/span&gt;! This is your very first post. Check &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9oZXhvLmlvL2RvY3Mv&#34;&gt;documentation&lt;/span&gt; for more info. If you get any problems when using Hexo, you can find the answer in &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9oZXhvLmlvL2RvY3MvdHJvdWJsZXNob290aW5nLmh0bWw=&#34;&gt;troubleshooting&lt;/span&gt; or you can ask me on &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9naXRodWIuY29tL2hleG9qcy9oZXhvL2lzc3Vlcw==&#34;&gt;GitHub&lt;/span&gt;.&lt;/p&gt;
&lt;h2 id=&#34;quick-start&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#quick-start&#34;&gt;#&lt;/a&gt; Quick Start&lt;/h2&gt;
&lt;h3 id=&#34;create-a-new-post&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#create-a-new-post&#34;&gt;#&lt;/a&gt; Create a new post&lt;/h3&gt;
&lt;p&gt;&lt;figure class=&#34;highlight bash&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;$ hexo new &lt;span class=&#34;string&#34;&gt;&amp;quot;My New Post&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;More info: &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvd3JpdGluZy5odG1s&#34;&gt;Writing&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;run-server&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#run-server&#34;&gt;#&lt;/a&gt; Run server&lt;/h3&gt;
&lt;p&gt;&lt;figure class=&#34;highlight bash&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;$ hexo server&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;More info: &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvc2VydmVyLmh0bWw=&#34;&gt;Server&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;generate-static-files&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#generate-static-files&#34;&gt;#&lt;/a&gt; Generate static files&lt;/h3&gt;
&lt;p&gt;&lt;figure class=&#34;highlight bash&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;$ hexo generate&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;More info: &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9oZXhvLmlvL2RvY3MvZ2VuZXJhdGluZy5odG1s&#34;&gt;Generating&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;deploy-to-remote-sites&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#deploy-to-remote-sites&#34;&gt;#&lt;/a&gt; Deploy to remote sites&lt;/h3&gt;
&lt;p&gt;&lt;figure class=&#34;highlight bash&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;$ hexo deploy&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;More info: &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvb25lLWNvbW1hbmQtZGVwbG95bWVudC5odG1s&#34;&gt;Deployment&lt;/span&gt;&lt;/p&gt;
 ]]></description>
        </item>
    </channel>
</rss>
